## Interpretable machine learning

This folder has three notebooks, one for each of the following methods to produce explanations for black-box predictions of machine learning models: [LIME](https://lime-ml.readthedocs.io/en/latest/), [Rulefit](https://github.com/christophM/rulefit) and [SHAP](https://shap.readthedocs.io/en/latest/index.html).

Making use of these tutorial notebooks, I have managed to develop and test applications for explaining predictions of classification models at work. In addition to demonstration codes, at the beginning of each notebook we find a brief theoretical discussion about the methods.

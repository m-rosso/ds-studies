{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid vs. random searches\n",
    "## Methodology development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search will be compared against random search based on their implementation using logistic regression and GBM as estimation methods. The tuning hyper-parameter of the first is *regularization parameter* $\\lambda$, while the second method has the following hyper-parameters to be set: *subsample* $\\eta$, *maximum depth* $J$, *learning rate* $v$ and *number of estimators* $M$.\n",
    "<br>\n",
    "<br>\n",
    "Grid search for $\\lambda$ will take place on the following set: $\\Theta_{\\lambda} = [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.25, 0.3, 0.5, 0.75, 1, 3, 10]$. For random search, its minimum and maximum values conceive the interval $(0.0001, 10)$ over which a three-modal random distribution will be defined: $Uniform(0.0001, 0.1)$, $Uniform(0.1, 1)$ and $Uniform(1, 10)$. A total of 10 random samples will be drawn, preserving the same density of values in each sub-interval $(0.0001, 0.1)$, $(0.1, 1)$ and $(1, 10)$ as found in $\\Theta_{\\lambda}$ - therefore, four random values from $(0.0001, 0.1)$, four from $(0.1, 1)$ and two from $(1, 10)$.\n",
    "<br>\n",
    "<br>\n",
    "When it comes to the definition of $(\\eta, J, v, M)$ for GBM estimation, grid search will look over $\\Theta = \\{0.75\\}x\\{1, 3, 5\\}x\\{0.0001, 0.01, 0.1\\}x\\{100, 250, 500\\}$, so $|\\Theta| = 27$. In order to keep things comparable, 20 random samples $(\\eta, J, v, M)$ will be extracted based on the following distributions for each hyper-parameter: $\\eta = 0.75$ will be kept constant, while $J \\in \\{1, 2, 3, 4, 5\\}$ and $M \\in \\{100, 101, ..., 500\\}$ will be defined from an ordinary random sampling. Finally, $v$ will come from $Uniform(0.0001, 0.1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook follows experiments design present in the first notebook of the series, and contains codes for implementing tests to compare grid and random searches. These tests, in their turn, will make use of Python scripts that generalize codes present here. A final notebook will assess and discuss results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "1. [Libraries](#libraries)<a href='#libraries'></a>.\n",
    "2. [Functions and classes](#functions_classes)<a href='#functions_classes'></a>.\n",
    "3. [Settings](#settings)<a href='#settings'></a>.\n",
    "4. [Importing data](#imports)<a href='#imports'></a>.\n",
    "    * [Categorical features](#categorical_features)<a href='#categorical_features'></a>.\n",
    "    * [Model assessment](#model_assessment)<a href='#model_assessment'></a>.\n",
    "    * [Classifying features](#classif_feat)<a href='#classif_feat'></a>.\n",
    "<br>\n",
    "<br>\n",
    "5. [Data pre-processing](#data_pre_proc)<a href='#data_pre_proc'></a>.\n",
    "    * [Assessing missing values](#assessing_missing)<a href='#assessing_missing'></a>.\n",
    "    * [Transforming numerical features](#num_transf)<a href='#num_transf'></a>.\n",
    "    * [Transforming categorical features](#categorical_transf)<a href='#categorical_transf'></a>.\n",
    "    * [Datasets structure](#datasets_structure)<a href='#datasets_structure'></a>.\n",
    "<br>\n",
    "<br>\n",
    "6. [Model estimation](#model_estimation)<a href='#model_estimation'></a>.\n",
    "    * [Grids of hyper-parameters](#grids)<a href='#grids'></a>.\n",
    "    * [Estimations](#estimations)<a href='#estimations'></a>.\n",
    "<br>\n",
    "<br>\n",
    "7. [Assessment of results](#assess_results)<a href='#assess_results'></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='libraries'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import progressbar\n",
    "from time import sleep\n",
    "\n",
    "from scipy.stats import uniform, norm, randint\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, auc, precision_recall_curve, brier_score_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functions_classes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import epoch_to_date, text_clean, is_velocity, get_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import log_transformation, standard_scale, recreate_missings, impute_missing\n",
    "from transformations import one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validation\n",
    "from validation import Kfolds_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='settings'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_id = str(int(time.time()))\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Declare whether to export results:\n",
    "export = False\n",
    "\n",
    "# Define a dataset id:\n",
    "s = 9098"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare whether to apply logarithmic transformation over numerical data:\n",
    "log_transform = True\n",
    "\n",
    "# Declare whether to standardize numerical data:\n",
    "standardize = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an estimation method ['logistic_regression', 'GBM']:\n",
    "method = 'logistic_regression'\n",
    "\n",
    "# Choose whether to perform random search (True) or grid search (False):\n",
    "random_search = False\n",
    "\n",
    "# Define the number of samples to implement random search:\n",
    "if method == 'logistic_regression':\n",
    "    n_samples = 10\n",
    "\n",
    "elif method == 'GBM':\n",
    "    n_samples = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_train for store 9098:\u001b[0m (7520, 2260).\n",
      "\u001b[1mShape of df_test for store 9098:\u001b[0m (11218, 2260).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGSMALLAREAREPUTATION()</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,10080)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,1440)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,21600)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,360)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,43200)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,60)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,64800)</th>\n",
       "      <th>BILLINGZIP(DOCUMENT,10080)</th>\n",
       "      <th>...</th>\n",
       "      <th>ZIPFIRST3REPUTATION()</th>\n",
       "      <th>ZIPFIRST5REPUTATION()</th>\n",
       "      <th>y</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_id</th>\n",
       "      <th>status</th>\n",
       "      <th>epoch</th>\n",
       "      <th>store_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.022820</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.39</td>\n",
       "      <td>449e1d8e-63aa-4f04-a865-a5559db83d1a</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577894e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.024314</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.84</td>\n",
       "      <td>248d5388-83de-468f-ad04-641492f16b22</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577894e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.054615</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.86</td>\n",
       "      <td>ab36eee7-ee22-4fcd-abaf-4437ec534d1d</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577914e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BILLINGLARGEAREAREPUTATION()  BILLINGSMALLAREAREPUTATION()  \\\n",
       "0                      0.022820                      0.008911   \n",
       "1                      0.024314                      0.007161   \n",
       "2                      0.054615                      0.006761   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,10080)  BILLINGZIP(CREDITCARD,1440)  \\\n",
       "0                           1.0                          1.0   \n",
       "1                           1.0                          1.0   \n",
       "2                           2.0                          1.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,21600)  BILLINGZIP(CREDITCARD,360)  \\\n",
       "0                           1.0                         1.0   \n",
       "1                           1.0                         1.0   \n",
       "2                           2.0                         1.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,43200)  BILLINGZIP(CREDITCARD,60)  \\\n",
       "0                           2.0                        1.0   \n",
       "1                           2.0                        1.0   \n",
       "2                           3.0                        1.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,64800)  BILLINGZIP(DOCUMENT,10080)  ...  \\\n",
       "0                           2.0                         1.0  ...   \n",
       "1                           3.0                         1.0  ...   \n",
       "2                           3.0                         1.0  ...   \n",
       "\n",
       "   ZIPFIRST3REPUTATION()  ZIPFIRST5REPUTATION()    y  order_amount  \\\n",
       "0               0.025636                    0.0  0.0        271.39   \n",
       "1               0.027638                    0.0  0.0        113.84   \n",
       "2               0.012398                    0.0  0.0        179.86   \n",
       "\n",
       "                               order_id    status         epoch  store_id  \\\n",
       "0  449e1d8e-63aa-4f04-a865-a5559db83d1a  APPROVED  1.577894e+12      9098   \n",
       "1  248d5388-83de-468f-ad04-641492f16b22  APPROVED  1.577894e+12      9098   \n",
       "2  ab36eee7-ee22-4fcd-abaf-4437ec534d1d  APPROVED  1.577914e+12      9098   \n",
       "\n",
       "   weight       date  \n",
       "0     1.0 2020-01-01  \n",
       "1     1.0 2020-01-01  \n",
       "2     1.0 2020-01-01  \n",
       "\n",
       "[3 rows x 2260 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data:\n",
    "os.chdir('/home/matheus_rosso/Arquivo/Features/Datasets/')\n",
    "\n",
    "df_train = pd.read_csv('new_additional_datasets/dataset_' + str(s) + '.csv',\n",
    "                       dtype={'order_id': str, 'store_id': int})\n",
    "df_train.drop_duplicates(['order_id', 'epoch', 'order_amount'], inplace=True)\n",
    "df_train['date'] = df_train.epoch.apply(epoch_to_date)\n",
    "\n",
    "# Dropping original categorical features:\n",
    "cat_vars = get_cat(df_train)\n",
    "c_vars = [c for c in list(df_train.columns) if 'C#' in c]\n",
    "na_vars = ['NA#' + c for c in cat_vars if 'NA#' + c in list(df_train.columns)]\n",
    "\n",
    "df_train = df_train.drop(c_vars, axis=1).drop(na_vars, axis=1)\n",
    "\n",
    "# Splitting data into train and test:\n",
    "df_test = df_train[(df_train.date > datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "df_train = df_train[(df_train.date <= datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "\n",
    "print('\\033[1mShape of df_train for store ' + str(s) + ':\\033[0m ' + str(df_train.shape) + '.')\n",
    "print('\\033[1mShape of df_test for store ' + str(s) + ':\\033[0m ' + str(df_test.shape) + '.')\n",
    "print('\\n')\n",
    "\n",
    "# Accessory variables:\n",
    "drop_vars = ['y', 'order_amount', 'store_id', 'order_id', 'status', 'epoch', 'date', 'weight']\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values:\n",
    "num_miss_train = df_train.isnull().sum().sum()\n",
    "num_miss_test = df_test.isnull().sum().sum()\n",
    "\n",
    "if num_miss_train > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(df_train.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "\n",
    "if num_miss_test > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(df_test.isnull().sum().sum()) + '.')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_features'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of categorical_train (training data):\u001b[0m (7520, 22).\n",
      "\u001b[1mNumber of orders (training data):\u001b[0m 7520.\n",
      "\n",
      "\n",
      "\u001b[1mShape of categorical_test (test data):\u001b[0m (11218, 22).\n",
      "\u001b[1mNumber of orders (test data):\u001b[0m 11218.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGCITY()</th>\n",
       "      <th>BILLINGSTATE()</th>\n",
       "      <th>BROWSER()</th>\n",
       "      <th>CREDITCARDBRAND()</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>...</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "      <th>y</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_id</th>\n",
       "      <th>status</th>\n",
       "      <th>epoch</th>\n",
       "      <th>store_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>MASTERCARD</td>\n",
       "      <td>BR</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>bancotoyota.com.br</td>\n",
       "      <td>F</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.39</td>\n",
       "      <td>449e1d8e-63aa-4f04-a865-a5559db83d1a</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577894e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>MASTERCARD</td>\n",
       "      <td>BR</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>F</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.84</td>\n",
       "      <td>248d5388-83de-468f-ad04-641492f16b22</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577894e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Mobile Safari</td>\n",
       "      <td>VISA</td>\n",
       "      <td>BR</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>recoder.com.br</td>\n",
       "      <td>M</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.86</td>\n",
       "      <td>ab36eee7-ee22-4fcd-abaf-4437ec534d1d</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577914e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>MASTERCARD</td>\n",
       "      <td>BR</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>F</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.45</td>\n",
       "      <td>34f6e7d5-eef6-4a2b-9ba5-2c3c2e9be47e</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577965e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>VISA</td>\n",
       "      <td>BR</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>F</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>302.30</td>\n",
       "      <td>4ecf9829-62a3-499a-ad08-fc1f858f2e01</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577970e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  BILLINGCITY() BILLINGSTATE()      BROWSER() CREDITCARDBRAND()  \\\n",
       "0     São Paulo             SP  Chrome Mobile        MASTERCARD   \n",
       "1     São Paulo             SP  Chrome Mobile        MASTERCARD   \n",
       "2     São Paulo             SP  Mobile Safari              VISA   \n",
       "3     São Paulo             SP         Chrome        MASTERCARD   \n",
       "4     São Paulo             SP         Chrome              VISA   \n",
       "\n",
       "  CREDITCARDCOUNTRY() CREDITCARDSUBTYPE()       EMAILDOMAIN()  \\\n",
       "0                  BR               BLACK  bancotoyota.com.br   \n",
       "1                  BR                GOLD           gmail.com   \n",
       "2                  BR            PLATINUM      recoder.com.br   \n",
       "3                  BR                GOLD           gmail.com   \n",
       "4                  BR            PLATINUM           gmail.com   \n",
       "\n",
       "  GENDERBYNAMEPTBR() IPGEOLOCATIONCITY() IPGEOLOCATIONCOUNTRY()  ...  \\\n",
       "0                  F           São Paulo                     BR  ...   \n",
       "1                  F           São Paulo                     BR  ...   \n",
       "2                  M           São Paulo                     BR  ...   \n",
       "3                  F           São Paulo                     BR  ...   \n",
       "4                  F           São Paulo                     BR  ...   \n",
       "\n",
       "  SHIPPINGSTATE() UTMSOURCELASTCLICK()    y order_amount  \\\n",
       "0              SP                  NaN  0.0       271.39   \n",
       "1              SP                  NaN  0.0       113.84   \n",
       "2              SP                  NaN  0.0       179.86   \n",
       "3              SP                  NaN  0.0        68.45   \n",
       "4              SP                  NaN  0.0       302.30   \n",
       "\n",
       "                               order_id    status         epoch store_id  \\\n",
       "0  449e1d8e-63aa-4f04-a865-a5559db83d1a  APPROVED  1.577894e+12     9098   \n",
       "1  248d5388-83de-468f-ad04-641492f16b22  APPROVED  1.577894e+12     9098   \n",
       "2  ab36eee7-ee22-4fcd-abaf-4437ec534d1d  APPROVED  1.577914e+12     9098   \n",
       "3  34f6e7d5-eef6-4a2b-9ba5-2c3c2e9be47e  APPROVED  1.577965e+12     9098   \n",
       "4  4ecf9829-62a3-499a-ad08-fc1f858f2e01  APPROVED  1.577970e+12     9098   \n",
       "\n",
       "   weight       date  \n",
       "0     1.0 2020-01-01  \n",
       "1     1.0 2020-01-01  \n",
       "2     1.0 2020-01-01  \n",
       "3     1.0 2020-01-02  \n",
       "4     1.0 2020-01-02  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_train = pd.read_csv('new_additional_datasets/categorical_features/dataset_' + str(s) + '.csv',\n",
    "                      dtype={'order_id': str, 'store_id': int})\n",
    "categorical_train.drop_duplicates(['order_id', 'epoch', 'order_amount'], inplace=True)\n",
    "\n",
    "categorical_train['date'] = categorical_train.epoch.apply(epoch_to_date)\n",
    "\n",
    "# Splitting data into train and test:\n",
    "categorical_test = categorical_train[(categorical_train.date > datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "categorical_train = categorical_train[(categorical_train.date <= datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "\n",
    "print('\\033[1mShape of categorical_train (training data):\\033[0m ' + str(categorical_train.shape) + '.')\n",
    "print('\\033[1mNumber of orders (training data):\\033[0m ' + str(categorical_train.order_id.nunique()) + '.')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mShape of categorical_test (test data):\\033[0m ' + str(categorical_test.shape) + '.')\n",
    "print('\\033[1mNumber of orders (test data):\\033[0m ' + str(categorical_test.order_id.nunique()) + '.')\n",
    "print('\\n')\n",
    "\n",
    "categorical_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAssessing missing values in categorical data (training data):\u001b[0m\n",
      "UTMSOURCELASTCLICK()      7114\n",
      "CREDITCARDSUBTYPE()       4859\n",
      "CREDITCARDCOUNTRY()       4842\n",
      "CREDITCARDBRAND()         4842\n",
      "IPGEOLOCATIONCITY()        122\n",
      "IPGEOLOCATIONCOUNTRY()      77\n",
      "BROWSER()                   77\n",
      "GENDERBYNAMEPTBR()           2\n",
      "SHIPPINGSTATE()              0\n",
      "SHIPPINGCITY()               0\n",
      "SELLERID()                   0\n",
      "EMAILDOMAIN()                0\n",
      "BILLINGSTATE()               0\n",
      "BILLINGCITY()                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mAssessing missing values in categorical data (training data):\\033[0m')\n",
    "print(categorical_train.drop(drop_vars, axis=1).isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAssessing missing values in categorical data (test data):\u001b[0m\n",
      "CREDITCARDSUBTYPE()       11218\n",
      "CREDITCARDCOUNTRY()       11218\n",
      "CREDITCARDBRAND()         11218\n",
      "UTMSOURCELASTCLICK()      10687\n",
      "IPGEOLOCATIONCITY()         358\n",
      "IPGEOLOCATIONCOUNTRY()       87\n",
      "BROWSER()                    73\n",
      "GENDERBYNAMEPTBR()            6\n",
      "SHIPPINGSTATE()               0\n",
      "SHIPPINGCITY()                0\n",
      "SELLERID()                    0\n",
      "EMAILDOMAIN()                 0\n",
      "BILLINGSTATE()                0\n",
      "BILLINGCITY()                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mAssessing missing values in categorical data (test data):\\033[0m')\n",
    "print(categorical_test.drop(drop_vars, axis=1).isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over categorical features:\n",
    "for f in categorical_train.drop(drop_vars, axis=1).columns:\n",
    "    # Training data\n",
    "    categorical_train[f] = categorical_train[f].apply(lambda x: 'NA_VALUE' if pd.isna(x) else x)\n",
    "    \n",
    "    # Test data:\n",
    "    categorical_test[f] = categorical_test[f].apply(lambda x: 'NA_VALUE' if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values:\n",
    "if categorical_train.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(categorical_train.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "\n",
    "if categorical_test.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(categorical_test.isnull().sum().sum()) + '.')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGCITY()</th>\n",
       "      <th>BILLINGSTATE()</th>\n",
       "      <th>BROWSER()</th>\n",
       "      <th>CREDITCARDBRAND()</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>...</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "      <th>y</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_id</th>\n",
       "      <th>status</th>\n",
       "      <th>epoch</th>\n",
       "      <th>store_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>chrome_mobile</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>br</td>\n",
       "      <td>black</td>\n",
       "      <td>bancotoyota.com.br</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.39</td>\n",
       "      <td>449e1d8e-63aa-4f04-a865-a5559db83d1a</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577894e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>chrome_mobile</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.84</td>\n",
       "      <td>248d5388-83de-468f-ad04-641492f16b22</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577894e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>mobile_safari</td>\n",
       "      <td>visa</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>recoder.com.br</td>\n",
       "      <td>m</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.86</td>\n",
       "      <td>ab36eee7-ee22-4fcd-abaf-4437ec534d1d</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577914e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>chrome</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.45</td>\n",
       "      <td>34f6e7d5-eef6-4a2b-9ba5-2c3c2e9be47e</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577965e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>chrome</td>\n",
       "      <td>visa</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>302.30</td>\n",
       "      <td>4ecf9829-62a3-499a-ad08-fc1f858f2e01</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577970e+12</td>\n",
       "      <td>9098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  BILLINGCITY() BILLINGSTATE()      BROWSER() CREDITCARDBRAND()  \\\n",
       "0     sao_paulo             sp  chrome_mobile        mastercard   \n",
       "1     sao_paulo             sp  chrome_mobile        mastercard   \n",
       "2     sao_paulo             sp  mobile_safari              visa   \n",
       "3     sao_paulo             sp         chrome        mastercard   \n",
       "4     sao_paulo             sp         chrome              visa   \n",
       "\n",
       "  CREDITCARDCOUNTRY() CREDITCARDSUBTYPE()       EMAILDOMAIN()  \\\n",
       "0                  br               black  bancotoyota.com.br   \n",
       "1                  br                gold           gmail.com   \n",
       "2                  br            platinum      recoder.com.br   \n",
       "3                  br                gold           gmail.com   \n",
       "4                  br            platinum           gmail.com   \n",
       "\n",
       "  GENDERBYNAMEPTBR() IPGEOLOCATIONCITY() IPGEOLOCATIONCOUNTRY()  ...  \\\n",
       "0                  f           sao_paulo                     br  ...   \n",
       "1                  f           sao_paulo                     br  ...   \n",
       "2                  m           sao_paulo                     br  ...   \n",
       "3                  f           sao_paulo                     br  ...   \n",
       "4                  f           sao_paulo                     br  ...   \n",
       "\n",
       "  SHIPPINGSTATE() UTMSOURCELASTCLICK()    y order_amount  \\\n",
       "0              sp             na_value  0.0       271.39   \n",
       "1              sp             na_value  0.0       113.84   \n",
       "2              sp             na_value  0.0       179.86   \n",
       "3              sp             na_value  0.0        68.45   \n",
       "4              sp             na_value  0.0       302.30   \n",
       "\n",
       "                               order_id    status         epoch store_id  \\\n",
       "0  449e1d8e-63aa-4f04-a865-a5559db83d1a  APPROVED  1.577894e+12     9098   \n",
       "1  248d5388-83de-468f-ad04-641492f16b22  APPROVED  1.577894e+12     9098   \n",
       "2  ab36eee7-ee22-4fcd-abaf-4437ec534d1d  APPROVED  1.577914e+12     9098   \n",
       "3  34f6e7d5-eef6-4a2b-9ba5-2c3c2e9be47e  APPROVED  1.577965e+12     9098   \n",
       "4  4ecf9829-62a3-499a-ad08-fc1f858f2e01  APPROVED  1.577970e+12     9098   \n",
       "\n",
       "   weight       date  \n",
       "0     1.0 2020-01-01  \n",
       "1     1.0 2020-01-01  \n",
       "2     1.0 2020-01-01  \n",
       "3     1.0 2020-01-02  \n",
       "4     1.0 2020-01-02  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_vars = [c for c in categorical_train.drop(drop_vars, axis=1) if 'NA#' in c]\n",
    "\n",
    "# Loop over categorical features:\n",
    "for f in categorical_train.drop(drop_vars, axis=1).drop(na_vars, axis=1).columns:\n",
    "    # Training data:\n",
    "    categorical_train[f] = categorical_train[f].apply(lambda x: text_clean(str(x)))\n",
    "    \n",
    "    # Test data:\n",
    "    categorical_test[f] = categorical_test[f].apply(lambda x: text_clean(str(x)))\n",
    "\n",
    "categorical_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_train for store 9098:\u001b[0m (7520, 2274).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGSMALLAREAREPUTATION()</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,10080)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,1440)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,21600)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,360)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,43200)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,60)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,64800)</th>\n",
       "      <th>BILLINGZIP(DOCUMENT,10080)</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>SELLERID()</th>\n",
       "      <th>SHIPPINGCITY()</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.022820</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>black</td>\n",
       "      <td>bancotoyota.com.br</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.024314</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.054615</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>recoder.com.br</td>\n",
       "      <td>m</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.035726</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.049755</td>\n",
       "      <td>0.018226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BILLINGLARGEAREAREPUTATION()  BILLINGSMALLAREAREPUTATION()  \\\n",
       "0                      0.022820                      0.008911   \n",
       "1                      0.024314                      0.007161   \n",
       "2                      0.054615                      0.006761   \n",
       "3                      0.035726                      0.009156   \n",
       "4                      0.049755                      0.018226   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,10080)  BILLINGZIP(CREDITCARD,1440)  \\\n",
       "0                           1.0                          1.0   \n",
       "1                           1.0                          1.0   \n",
       "2                           2.0                          1.0   \n",
       "3                           1.0                          1.0   \n",
       "4                           1.0                          1.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,21600)  BILLINGZIP(CREDITCARD,360)  \\\n",
       "0                           1.0                         1.0   \n",
       "1                           1.0                         1.0   \n",
       "2                           2.0                         1.0   \n",
       "3                           1.0                         1.0   \n",
       "4                           1.0                         1.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,43200)  BILLINGZIP(CREDITCARD,60)  \\\n",
       "0                           2.0                        1.0   \n",
       "1                           2.0                        1.0   \n",
       "2                           3.0                        1.0   \n",
       "3                           1.0                        1.0   \n",
       "4                           1.0                        1.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,64800)  BILLINGZIP(DOCUMENT,10080)  ...  \\\n",
       "0                           2.0                         1.0  ...   \n",
       "1                           3.0                         1.0  ...   \n",
       "2                           3.0                         1.0  ...   \n",
       "3                           2.0                         1.0  ...   \n",
       "4                           3.0                         1.0  ...   \n",
       "\n",
       "   CREDITCARDCOUNTRY()  CREDITCARDSUBTYPE()       EMAILDOMAIN()  \\\n",
       "0                   br                black  bancotoyota.com.br   \n",
       "1                   br                 gold           gmail.com   \n",
       "2                   br             platinum      recoder.com.br   \n",
       "3                   br                 gold           gmail.com   \n",
       "4                   br             platinum           gmail.com   \n",
       "\n",
       "   GENDERBYNAMEPTBR()  IPGEOLOCATIONCITY()  IPGEOLOCATIONCOUNTRY()  \\\n",
       "0                   f            sao_paulo                      br   \n",
       "1                   f            sao_paulo                      br   \n",
       "2                   m            sao_paulo                      br   \n",
       "3                   f            sao_paulo                      br   \n",
       "4                   f            sao_paulo                      br   \n",
       "\n",
       "   SELLERID()  SHIPPINGCITY()  SHIPPINGSTATE()  UTMSOURCELASTCLICK()  \n",
       "0        none       sao_paulo               sp              na_value  \n",
       "1        none       sao_paulo               sp              na_value  \n",
       "2        none       sao_paulo               sp              na_value  \n",
       "3        none       sao_paulo               sp              na_value  \n",
       "4        none       sao_paulo               sp              na_value  \n",
       "\n",
       "[5 rows x 2274 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data:\n",
    "df_train = df_train.merge(categorical_train[[f for f in categorical_train.columns if (f not in drop_vars) |\n",
    "                                             (f == 'order_id')]],\n",
    "                          on='order_id', how='left')\n",
    "\n",
    "print('\\033[1mShape of df_train for store ' + str(s) + ':\\033[0m ' + str(df_train.shape) + '.')\n",
    "print('\\n')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_test for store 9098:\u001b[0m (11218, 2274).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGSMALLAREAREPUTATION()</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,10080)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,1440)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,21600)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,360)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,43200)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,60)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,64800)</th>\n",
       "      <th>BILLINGZIP(DOCUMENT,10080)</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>SELLERID()</th>\n",
       "      <th>SHIPPINGCITY()</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.034498</td>\n",
       "      <td>0.013024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>m</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>13</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.030711</td>\n",
       "      <td>0.007754</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>35</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.027144</td>\n",
       "      <td>0.011135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>yahoo.com.br</td>\n",
       "      <td>m</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>13</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.050302</td>\n",
       "      <td>0.005572</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>yahoo.com.br</td>\n",
       "      <td>f</td>\n",
       "      <td>richmond</td>\n",
       "      <td>gb</td>\n",
       "      <td>13</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>m</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>13</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BILLINGLARGEAREAREPUTATION()  BILLINGSMALLAREAREPUTATION()  \\\n",
       "0                      0.034498                      0.013024   \n",
       "1                      0.030711                      0.007754   \n",
       "2                      0.027144                      0.011135   \n",
       "3                      0.050302                      0.005572   \n",
       "4                      0.002414                      0.002414   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,10080)  BILLINGZIP(CREDITCARD,1440)  \\\n",
       "0                           1.0                          1.0   \n",
       "1                           2.0                          1.0   \n",
       "2                           1.0                          1.0   \n",
       "3                           1.0                          1.0   \n",
       "4                           1.0                          1.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,21600)  BILLINGZIP(CREDITCARD,360)  \\\n",
       "0                           1.0                         1.0   \n",
       "1                           5.0                         1.0   \n",
       "2                           2.0                         1.0   \n",
       "3                           1.0                         1.0   \n",
       "4                           1.0                         1.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,43200)  BILLINGZIP(CREDITCARD,60)  \\\n",
       "0                           2.0                        1.0   \n",
       "1                           5.0                        1.0   \n",
       "2                           2.0                        1.0   \n",
       "3                           1.0                        1.0   \n",
       "4                           1.0                        1.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,64800)  BILLINGZIP(DOCUMENT,10080)  ...  \\\n",
       "0                           2.0                         1.0  ...   \n",
       "1                           5.0                         2.0  ...   \n",
       "2                           2.0                         1.0  ...   \n",
       "3                           1.0                         1.0  ...   \n",
       "4                           2.0                         1.0  ...   \n",
       "\n",
       "   CREDITCARDCOUNTRY()  CREDITCARDSUBTYPE()  EMAILDOMAIN()  \\\n",
       "0             na_value             na_value      gmail.com   \n",
       "1             na_value             na_value      gmail.com   \n",
       "2             na_value             na_value   yahoo.com.br   \n",
       "3             na_value             na_value   yahoo.com.br   \n",
       "4             na_value             na_value      gmail.com   \n",
       "\n",
       "   GENDERBYNAMEPTBR()  IPGEOLOCATIONCITY()  IPGEOLOCATIONCOUNTRY()  \\\n",
       "0                   m            sao_paulo                      br   \n",
       "1                   f            sao_paulo                      br   \n",
       "2                   m            sao_paulo                      br   \n",
       "3                   f             richmond                      gb   \n",
       "4                   m            sao_paulo                      br   \n",
       "\n",
       "   SELLERID()  SHIPPINGCITY()  SHIPPINGSTATE()  UTMSOURCELASTCLICK()  \n",
       "0          13       sao_paulo               sp              na_value  \n",
       "1          35       sao_paulo               sp              na_value  \n",
       "2          13       sao_paulo               sp              na_value  \n",
       "3          13       sao_paulo               sp              na_value  \n",
       "4          13       sao_paulo               sp              na_value  \n",
       "\n",
       "[5 rows x 2274 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data:\n",
    "df_test = df_test.merge(categorical_test[[f for f in categorical_test.columns if (f not in drop_vars) |\n",
    "                                          (f == 'order_id')]],\n",
    "                        on='order_id', how='left')\n",
    "\n",
    "print('\\033[1mShape of df_test for store ' + str(s) + ':\\033[0m ' + str(df_test.shape) + '.')\n",
    "print('\\n')\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values (training data):\n",
    "if df_train.isnull().sum().sum() != num_miss_train:\n",
    "    print('\\033[1mInconsistent number of overall missings values (training data)!\\033[0m')\n",
    "    print('\\n')\n",
    "\n",
    "# Assessing missing values (test data):\n",
    "if df_test.isnull().sum().sum() != num_miss_test:\n",
    "    print('\\033[1mInconsistent number of overall missings values (test data)!\\033[0m')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_assessment'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with information on model structure and performance:\n",
    "os.chdir('/home/matheus_rosso/Arquivo/Materiais/Codes/grid_random_searches/')\n",
    "\n",
    "if 'model_assessment.json' not in os.listdir('Datasets'):\n",
    "    model_assessment = {}\n",
    "\n",
    "else:\n",
    "    with open('Datasets/model_assessment.json') as json_file:\n",
    "        model_assessment = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classif_feat'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cont_vars</td>\n",
       "      <td>1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>missing_vars</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>binary_vars</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cat_vars</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>drop_vars</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          class  frequency\n",
       "3     cont_vars       1551\n",
       "1  missing_vars        480\n",
       "2   binary_vars         34\n",
       "0      cat_vars         14\n",
       "4     drop_vars          8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical features:\n",
    "cat_vars = list(categorical_train.drop(drop_vars, axis=1).columns)\n",
    "\n",
    "# Dummy variables indicating missing value status:\n",
    "missing_vars = [c for c in list(df_train.drop(drop_vars, axis=1).columns) if ('NA#' in c)]\n",
    "\n",
    "# Dropping features with no variance:\n",
    "no_variance = [c for c in df_train.drop(drop_vars, axis=1).drop(cat_vars,\n",
    "                                                                axis=1).drop(missing_vars,\n",
    "                                                                             axis=1) if df_train[c].var()==0]\n",
    "\n",
    "if len(no_variance) > 0:\n",
    "    df_train.drop(no_variance, axis=1, inplace=True)\n",
    "    df_test.drop(no_variance, axis=1, inplace=True)\n",
    "\n",
    "# Numerical features:\n",
    "cont_vars = [c for c in  list(df_train.drop(drop_vars, axis=1).columns) if is_velocity(c)]\n",
    "\n",
    "# Binary features:\n",
    "binary_vars = [c for c in list(df_train.drop([c for c in df_train.columns if (c in drop_vars) |\n",
    "                                             (c in cat_vars) | (c in missing_vars) | (c in cont_vars)],\n",
    "                                             axis=1).columns) if set(df_train[c].unique()) == set([0,1])]\n",
    "\n",
    "# Updating the list of numerical features:\n",
    "for c in list(df_train.drop(drop_vars, axis=1).columns):\n",
    "    if (c not in cat_vars) & (c not in missing_vars) & (c not in cont_vars) & (c not in binary_vars):\n",
    "        cont_vars.append(c)\n",
    "\n",
    "# Dataframe presenting the frequency of features by class:\n",
    "feats_assess = pd.DataFrame(data={\n",
    "    'class': ['cat_vars', 'missing_vars', 'binary_vars', 'cont_vars', 'drop_vars'],\n",
    "    'frequency': [len(cat_vars), len(missing_vars), len(binary_vars), len(cont_vars), len(drop_vars)]\n",
    "})\n",
    "feats_assess.sort_values('frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_pre_proc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing_missing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vars = [f for f in df_train.columns if 'NA#' in f]\n",
    "\n",
    "# Loop over variables with missing values:\n",
    "for f in [c for c in missing_vars if c.replace('NA#', '') not in cat_vars]:\n",
    "    if f.replace('NA#', '') in df_train.columns:\n",
    "        # Training data:\n",
    "        df_train[f.replace('NA#', '')] = recreate_missings(df_train[f.replace('NA#', '')], df_train[f])\n",
    "        \n",
    "        # Test data:\n",
    "        df_test[f.replace('NA#', '')] = recreate_missings(df_test[f.replace('NA#', '')], df_test[f])\n",
    "    else:\n",
    "        df_train.drop([f], axis=1, inplace=True)\n",
    "        \n",
    "        df_test.drop([f], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all variables with missing value status:\n",
    "df_train.drop([f for f in df_train.columns if 'NA#' in f], axis=1, inplace=True)\n",
    "\n",
    "df_test.drop([f for f in df_test.columns if 'NA#' in f], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describing the frequency of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of features with missings:\u001b[0m 460 out of 1607 features (28.62%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 1395 out of 7520 observations (18.55%).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>missings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>USRNAVCOUNT(9,1h)</td>\n",
       "      <td>7409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GFINGERPRINT(TOTAL_AMOUNT,60)</td>\n",
       "      <td>7408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CUSTNAVCOUNT(ta,30min)</td>\n",
       "      <td>7396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FINGERPRINT(TOTAL_AMOUNT,360)</td>\n",
       "      <td>7390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>GTELEPHONE(TOTAL_AMOUNT,60)</td>\n",
       "      <td>7385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>NAME(TOTAL_AMOUNT,360)</td>\n",
       "      <td>7382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>USRNAVCOUNT(ta,30min)</td>\n",
       "      <td>7381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>EMAIL(TOTAL_AMOUNT,360)</td>\n",
       "      <td>7381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>CUSTNAVCOUNT(ta,1h)</td>\n",
       "      <td>7379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>TELEPHONE(TOTAL_AMOUNT,360)</td>\n",
       "      <td>7375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature  missings\n",
       "training_data                                         \n",
       "0                          USRNAVCOUNT(9,1h)      7409\n",
       "1              GFINGERPRINT(TOTAL_AMOUNT,60)      7408\n",
       "2                     CUSTNAVCOUNT(ta,30min)      7396\n",
       "3              FINGERPRINT(TOTAL_AMOUNT,360)      7390\n",
       "4                GTELEPHONE(TOTAL_AMOUNT,60)      7385\n",
       "5                     NAME(TOTAL_AMOUNT,360)      7382\n",
       "6                      USRNAVCOUNT(ta,30min)      7381\n",
       "7                    EMAIL(TOTAL_AMOUNT,360)      7381\n",
       "8                        CUSTNAVCOUNT(ta,1h)      7379\n",
       "9                TELEPHONE(TOTAL_AMOUNT,360)      7375"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with the number of missings by feature (training data):\n",
    "missings_dict = df_train.isnull().sum().sort_values(ascending=False).to_dict()\n",
    "\n",
    "missings_assess_train = pd.DataFrame(data={\n",
    "    'feature': list(missings_dict.keys()),\n",
    "    'missings': list(missings_dict.values())\n",
    "})\n",
    "\n",
    "print('\\033[1mNumber of features with missings:\\033[0m {}'.format(sum(missings_assess_train.missings > 0)) +\n",
    "      ' out of {} features'.format(len(missings_assess_train)) +\n",
    "      ' ({}%).'.format(round((sum(missings_assess_train.missings > 0)/len(missings_assess_train))*100, 2)))\n",
    "print('\\033[1mAverage number of missings:\\033[0m {}'.format(int(missings_assess_train.missings.mean())) +\n",
    "      ' out of {} observations'.format(len(df_train)) +\n",
    "      ' ({}%).'.format(round((int(missings_assess_train.missings.mean())/len(df_train))*100,2)))\n",
    "print('\\n')\n",
    "\n",
    "missings_assess_train.index.name = 'training_data'\n",
    "missings_assess_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of features with missings:\u001b[0m 460 out of 1607 features (28.62%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 2657 out of 11218 observations (23.69%).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>missings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SHIPPING_NAME(IP,43200)</td>\n",
       "      <td>11218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SHIPPING_NAME(FINGERPRINT,1440)</td>\n",
       "      <td>11218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SHIPPING_NAME(EMAIL,10080)</td>\n",
       "      <td>11218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SHIPPING_NAME(EMAIL,1440)</td>\n",
       "      <td>11218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SHIPPING_NAME(EMAIL,21600)</td>\n",
       "      <td>11218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>SHIPPING_NAME(EMAIL,360)</td>\n",
       "      <td>11218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>SHIPPING_NAME(EMAIL,43200)</td>\n",
       "      <td>11218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>SHIPPING_NAME(EMAIL,60)</td>\n",
       "      <td>11218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SHIPPING_NAME(EMAIL,64800)</td>\n",
       "      <td>11218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>SHIPPING_NAME(FINGERPRINT,10080)</td>\n",
       "      <td>11218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    feature  missings\n",
       "test_data                                            \n",
       "0                   SHIPPING_NAME(IP,43200)     11218\n",
       "1           SHIPPING_NAME(FINGERPRINT,1440)     11218\n",
       "2                SHIPPING_NAME(EMAIL,10080)     11218\n",
       "3                 SHIPPING_NAME(EMAIL,1440)     11218\n",
       "4                SHIPPING_NAME(EMAIL,21600)     11218\n",
       "5                  SHIPPING_NAME(EMAIL,360)     11218\n",
       "6                SHIPPING_NAME(EMAIL,43200)     11218\n",
       "7                   SHIPPING_NAME(EMAIL,60)     11218\n",
       "8                SHIPPING_NAME(EMAIL,64800)     11218\n",
       "9          SHIPPING_NAME(FINGERPRINT,10080)     11218"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with the number of missings by feature (test data):\n",
    "missings_dict = df_test.isnull().sum().sort_values(ascending=False).to_dict()\n",
    "\n",
    "missings_assess_test = pd.DataFrame(data={\n",
    "    'feature': list(missings_dict.keys()),\n",
    "    'missings': list(missings_dict.values())\n",
    "})\n",
    "\n",
    "print('\\033[1mNumber of features with missings:\\033[0m {}'.format(sum(missings_assess_test.missings > 0)) +\n",
    "      ' out of {} features'.format(len(missings_assess_test)) +\n",
    "      ' ({}%).'.format(round((sum(missings_assess_test.missings > 0)/len(missings_assess_test))*100, 2)))\n",
    "print('\\033[1mAverage number of missings:\\033[0m {}'.format(int(missings_assess_test.missings.mean())) +\n",
    "      ' out of {} observations'.format(len(df_test)) +\n",
    "      ' ({}%).'.format(round((int(missings_assess_test.missings.mean())/len(df_test))*100,2)))\n",
    "print('\\n')\n",
    "missings_assess_test.index.name = 'test_data'\n",
    "missings_assess_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='num_transf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logarithmic transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mAPPLYING LOGARITHMIC TRANSFORMATION OVER NUMERICAL DATA\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mNumber of overall missings detected (before logarithmic transformation):\u001b[0m 2242917.\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 1551.\n",
      "\u001b[1mNumber of overall missings detected (after logarithmic transformation):\u001b[0m 2242917.\n",
      "\n",
      "\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mNumber of overall missings detected (before logarithmic transformation):\u001b[0m 4271178.\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 1551.\n",
      "\u001b[1mNumber of overall missings detected (after logarithmic transformation):\u001b[0m 4271178.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mAPPLYING LOGARITHMIC TRANSFORMATION OVER NUMERICAL DATA\\033[0m')\n",
    "print('\\n')\n",
    "# Variables that should not be log-transformed:\n",
    "not_log = [c for c in df_train.columns if c not in cont_vars]\n",
    "\n",
    "if log_transform:\n",
    "    print('\\033[1mTraining data:\\033[0m')\n",
    "\n",
    "    # Assessing missing values (before logarithmic transformation):\n",
    "    num_miss_train = df_train.isnull().sum().sum()\n",
    "    if num_miss_train > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (before logarithmic transformation):\\033[0m ' +\n",
    "              str(num_miss_train) + '.')\n",
    "\n",
    "    log_transf = log_transformation(not_log=not_log)\n",
    "    log_transf.transform(df_train)\n",
    "    df_train = log_transf.log_transformed\n",
    "\n",
    "    # Assessing missing values (after logarithmic transformation):\n",
    "    num_miss_train_log = df_train.isnull().sum().sum()\n",
    "    if num_miss_train_log > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (after logarithmic transformation):\\033[0m ' + \n",
    "              str(num_miss_train_log) + '.')\n",
    "\n",
    "    # Checking consistency in the number of missings:\n",
    "    if num_miss_train_log != num_miss_train:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\033[1mTest data:\\033[0m')\n",
    "\n",
    "    # Assessing missing values (before logarithmic transformation):\n",
    "    num_miss_test = df_test.isnull().sum().sum()\n",
    "    if num_miss_test > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (before logarithmic transformation):\\033[0m ' +\n",
    "              str(num_miss_test) + '.')\n",
    "\n",
    "    log_transf = log_transformation(not_log=not_log)\n",
    "    log_transf.transform(df_test)\n",
    "    df_test = log_transf.log_transformed\n",
    "\n",
    "    # Assessing missing values (after logarithmic transformation):\n",
    "    num_miss_test_log = df_test.isnull().sum().sum()\n",
    "    if num_miss_test_log > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (after logarithmic transformation):\\033[0m ' + \n",
    "              str(num_miss_test_log) + '.')\n",
    "\n",
    "    # Checking consistency in the number of missings:\n",
    "    if num_miss_test_log != num_miss_test:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "else:\n",
    "    print('\\033[1mNo transformation performed!\\033[0m')\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mAPPLYING STANDARD SCALE TRANSFORMATION OVER NUMERICAL DATA\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mShape of df_train_scaled (after scaling):\u001b[0m (7520, 1607).\n",
      "\u001b[1mNumber of overall missings:\u001b[0m 2242917.\n",
      "\n",
      "\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mShape of df_test_scaled (after scaling):\u001b[0m (11218, 1607).\n",
      "\u001b[1mNumber of overall missings:\u001b[0m 4271178.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mAPPLYING STANDARD SCALE TRANSFORMATION OVER NUMERICAL DATA\\033[0m')\n",
    "print('\\n')\n",
    "# Inputs that should not be standardized:\n",
    "not_stand = [c for c in df_train.columns if c.replace('L#', '') not in cont_vars]\n",
    "\n",
    "if standardize:\n",
    "    print('\\033[1mTraining data:\\033[0m')\n",
    "\n",
    "    stand_scale = standard_scale(not_stand = not_stand)\n",
    "    \n",
    "    stand_scale.scale(train = df_train, test = df_test)\n",
    "    \n",
    "    df_train_scaled = stand_scale.train_scaled\n",
    "    print('\\033[1mShape of df_train_scaled (after scaling):\\033[0m ' + str(df_train_scaled.shape) + '.')\n",
    "\n",
    "    # Assessing missing values (after standardizing numerical features):\n",
    "    num_miss_train = df_train.isnull().sum().sum()\n",
    "    num_miss_train_scaled = df_train_scaled.isnull().sum().sum()\n",
    "    if num_miss_train_scaled > 0:\n",
    "        print('\\033[1mNumber of overall missings:\\033[0m ' + str(num_miss_train_scaled) + '.')\n",
    "    else:\n",
    "        print('\\033[1mNo missing values detected (training data)!\\033[0m')\n",
    "\n",
    "    if num_miss_train_scaled != num_miss_train:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "    \n",
    "    print('\\n')\n",
    "    print('\\033[1mTest data:\\033[0m')\n",
    "    df_test_scaled = stand_scale.test_scaled\n",
    "    print('\\033[1mShape of df_test_scaled (after scaling):\\033[0m ' + str(df_test_scaled.shape) + '.')\n",
    "\n",
    "    # Assessing missing values (after standardizing numerical features):\n",
    "    num_miss_test = df_test.isnull().sum().sum()\n",
    "    num_miss_test_scaled = df_test_scaled.isnull().sum().sum()\n",
    "    if num_miss_test_scaled > 0:\n",
    "        print('\\033[1mNumber of overall missings:\\033[0m ' + str(num_miss_test_scaled) + '.')\n",
    "    else:\n",
    "        print('\\033[1mNo missing values detected (test data)!\\033[0m')\n",
    "\n",
    "    if num_miss_test_scaled != num_miss_test:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "else:\n",
    "    df_train_scaled = df_train.copy()\n",
    "    df_test_scaled = df_test.copy()\n",
    "    \n",
    "    print('\\033[1mNo transformation performed!\\033[0m')\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mTREATING MISSING VALUES\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mNumber of overall missing values detected before treatment:\u001b[0m 2242917.\n",
      "\u001b[1mNumber of overall missing values detected during treatment:\u001b[0m 2242917.\n",
      "\n",
      "\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mNumber of overall missing values detected before treatment:\u001b[0m 4271178.\n",
      "\u001b[1mNumber of overall missing values detected during treatment:\u001b[0m 4271178.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mTREATING MISSING VALUES\\033[0m')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mTraining data:\\033[0m')\n",
    "num_miss_train = df_train_scaled.isnull().sum().sum()\n",
    "print('\\033[1mNumber of overall missing values detected before treatment:\\033[0m ' +\n",
    "      str(num_miss_train) + '.')\n",
    "\n",
    "# Loop over features:\n",
    "for f in df_train_scaled.drop(drop_vars, axis=1):\n",
    "    # Checking if there is missing values for a given feature:\n",
    "    if df_train_scaled[f].isnull().sum() > 0:\n",
    "        check_missing = impute_missing(df_train_scaled[f])\n",
    "        df_train_scaled[f] = check_missing['var']\n",
    "        df_train_scaled['NA#' + f.replace('L#', '')] = check_missing['missing_var']\n",
    "\n",
    "num_miss_train_treat = int(sum([sum(df_train_scaled[f]) for f in df_train_scaled.columns if 'NA#' in f]))\n",
    "print('\\033[1mNumber of overall missing values detected during treatment:\\033[0m ' +\n",
    "      str(num_miss_train_treat) + '.')\n",
    "\n",
    "if num_miss_train_treat != num_miss_train:\n",
    "    print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "if df_train_scaled.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(df_train_scaled.isnull().sum().sum()) + '.')\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mTest data:\\033[0m')\n",
    "num_miss_test = df_test_scaled.isnull().sum().sum()\n",
    "num_miss_test_treat = 0\n",
    "print('\\033[1mNumber of overall missing values detected before treatment:\\033[0m ' + str(num_miss_test) + '.')\n",
    "\n",
    "# Loop over features:\n",
    "for f in df_test_scaled.drop(drop_vars, axis=1):\n",
    "    # Check if there is dummy variable of missing value status for training data:\n",
    "    if 'NA#' + f.replace('L#', '') in list(df_train_scaled.columns):\n",
    "        check_missing = impute_missing(df_test_scaled[f])\n",
    "        df_test_scaled[f] = check_missing['var']\n",
    "        df_test_scaled['NA#' + f.replace('L#', '')] = check_missing['missing_var']\n",
    "    else:\n",
    "        # Checking if there are missings for variables without missings in training data:\n",
    "        if df_test_scaled[f].isnull().sum() > 0:\n",
    "            num_miss_test_treat += df_test_scaled[f].isnull().sum()\n",
    "            df_test_scaled[f].fillna(0, axis=0, inplace=True)\n",
    "\n",
    "num_miss_test_treat += int(sum([sum(df_test_scaled[f]) for f in df_test_scaled.columns if 'NA#' in f]))\n",
    "print('\\033[1mNumber of overall missing values detected during treatment:\\033[0m ' +\n",
    "      str(num_miss_test_treat) + '.')\n",
    "\n",
    "if num_miss_test_treat != num_miss_test:\n",
    "    print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "if df_test_scaled.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(df_test_scaled.isnull().sum().sum()) + '.')\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_transf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dummies through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of categorical features:\u001b[0m 14.\n",
      "\u001b[1mNumber of overall selected dummies:\u001b[0m 51.\n",
      "\u001b[1mShape of dummies_train for store 9098:\u001b[0m (7520, 51).\n",
      "\u001b[1mShape of dummies_test for store 9098:\u001b[0m (11218, 51).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C#BILLINGCITY()#BARUERI</th>\n",
       "      <th>C#BILLINGCITY()#OSASCO</th>\n",
       "      <th>C#BILLINGCITY()#SANTANA_DE_PARNAIBA</th>\n",
       "      <th>C#BILLINGCITY()#SAO_PAULO</th>\n",
       "      <th>C#BROWSER()#CHROME</th>\n",
       "      <th>C#BROWSER()#CHROME_MOBILE</th>\n",
       "      <th>C#BROWSER()#FIREFOX</th>\n",
       "      <th>C#BROWSER()#MOBILE_SAFARI</th>\n",
       "      <th>C#BROWSER()#NA_VALUE</th>\n",
       "      <th>C#BROWSER()#SAFARI</th>\n",
       "      <th>...</th>\n",
       "      <th>C#SELLERID()#31</th>\n",
       "      <th>C#SELLERID()#35</th>\n",
       "      <th>C#SELLERID()#NONE</th>\n",
       "      <th>C#SHIPPINGCITY()#BARUERI</th>\n",
       "      <th>C#SHIPPINGCITY()#OSASCO</th>\n",
       "      <th>C#SHIPPINGCITY()#SANTANA_DE_PARNAIBA</th>\n",
       "      <th>C#SHIPPINGCITY()#SAO_PAULO</th>\n",
       "      <th>C#UTMSOURCELASTCLICK()#EMAIL</th>\n",
       "      <th>C#UTMSOURCELASTCLICK()#FACEBOOK</th>\n",
       "      <th>C#UTMSOURCELASTCLICK()#NA_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   C#BILLINGCITY()#BARUERI  C#BILLINGCITY()#OSASCO  \\\n",
       "0                        0                       0   \n",
       "1                        0                       0   \n",
       "2                        0                       0   \n",
       "3                        0                       0   \n",
       "4                        0                       0   \n",
       "\n",
       "   C#BILLINGCITY()#SANTANA_DE_PARNAIBA  C#BILLINGCITY()#SAO_PAULO  \\\n",
       "0                                    0                          1   \n",
       "1                                    0                          1   \n",
       "2                                    0                          1   \n",
       "3                                    0                          1   \n",
       "4                                    0                          1   \n",
       "\n",
       "   C#BROWSER()#CHROME  C#BROWSER()#CHROME_MOBILE  C#BROWSER()#FIREFOX  \\\n",
       "0                   0                          1                    0   \n",
       "1                   0                          1                    0   \n",
       "2                   0                          0                    0   \n",
       "3                   1                          0                    0   \n",
       "4                   1                          0                    0   \n",
       "\n",
       "   C#BROWSER()#MOBILE_SAFARI  C#BROWSER()#NA_VALUE  C#BROWSER()#SAFARI  ...  \\\n",
       "0                          0                     0                   0  ...   \n",
       "1                          0                     0                   0  ...   \n",
       "2                          1                     0                   0  ...   \n",
       "3                          0                     0                   0  ...   \n",
       "4                          0                     0                   0  ...   \n",
       "\n",
       "   C#SELLERID()#31  C#SELLERID()#35  C#SELLERID()#NONE  \\\n",
       "0                0                0                  1   \n",
       "1                0                0                  1   \n",
       "2                0                0                  1   \n",
       "3                0                0                  1   \n",
       "4                0                0                  1   \n",
       "\n",
       "   C#SHIPPINGCITY()#BARUERI  C#SHIPPINGCITY()#OSASCO  \\\n",
       "0                         0                        0   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         0                        0   \n",
       "4                         0                        0   \n",
       "\n",
       "   C#SHIPPINGCITY()#SANTANA_DE_PARNAIBA  C#SHIPPINGCITY()#SAO_PAULO  \\\n",
       "0                                     0                           1   \n",
       "1                                     0                           1   \n",
       "2                                     0                           1   \n",
       "3                                     0                           1   \n",
       "4                                     0                           1   \n",
       "\n",
       "   C#UTMSOURCELASTCLICK()#EMAIL  C#UTMSOURCELASTCLICK()#FACEBOOK  \\\n",
       "0                             0                                0   \n",
       "1                             0                                0   \n",
       "2                             0                                0   \n",
       "3                             0                                0   \n",
       "4                             0                                0   \n",
       "\n",
       "   C#UTMSOURCELASTCLICK()#NA_VALUE  \n",
       "0                                1  \n",
       "1                                1  \n",
       "2                                1  \n",
       "3                                1  \n",
       "4                                1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create object for one-hot encoding:\n",
    "categorical_transf = one_hot_encoding(categorical_features = cat_vars)\n",
    "\n",
    "# Creating dummies:\n",
    "categorical_transf.create_dummies(categorical_train = categorical_train,\n",
    "                                  categorical_test = categorical_test)\n",
    "\n",
    "# Selected dummies:\n",
    "dummy_vars = list(categorical_transf.dummies_train.columns)\n",
    "\n",
    "# Training data:\n",
    "dummies_train = categorical_transf.dummies_train\n",
    "dummies_train.index = df_train_scaled.index\n",
    "\n",
    "# Test data:\n",
    "dummies_test = categorical_transf.dummies_test\n",
    "dummies_test.index = df_test_scaled.index\n",
    "\n",
    "# Dropping original categorical features:\n",
    "df_train_scaled.drop(cat_vars, axis=1, inplace=True)\n",
    "df_test_scaled.drop(cat_vars, axis=1, inplace=True)\n",
    "\n",
    "print('\\033[1mNumber of categorical features:\\033[0m {}.'.format(len(categorical_transf.categorical_features)))\n",
    "print('\\033[1mNumber of overall selected dummies:\\033[0m {}.'.format(dummies_train.shape[1]))\n",
    "print('\\033[1mShape of dummies_train for store ' + str(s) + ':\\033[0m ' +\n",
    "      str(dummies_train.shape) + '.')\n",
    "print('\\033[1mShape of dummies_test for store ' + str(s) + ':\\033[0m ' +\n",
    "      str(dummies_test.shape) + '.')\n",
    "print('\\n')\n",
    "\n",
    "dummies_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_train_scaled for store 9098:\u001b[0m (7520, 2104).\n",
      "\u001b[1mShape of df_test_scaled for store 9098:\u001b[0m (11218, 2104).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUREAUBILLCITY()</th>\n",
       "      <th>BUREAUBILLSTATE()</th>\n",
       "      <th>BUREAUDOB()</th>\n",
       "      <th>BUREAUEMAIL()</th>\n",
       "      <th>BUREAUPHONE()</th>\n",
       "      <th>BUREAUPHONEAREACODE()</th>\n",
       "      <th>BUREAUSHIPCITY()</th>\n",
       "      <th>BUREAUSHIPSTATE()</th>\n",
       "      <th>CREDITCARDCOUNTRYSAMEASBILLING()</th>\n",
       "      <th>CREDITCARDCOUNTRYSAMEASSHIPPING()</th>\n",
       "      <th>...</th>\n",
       "      <th>C#SELLERID()#31</th>\n",
       "      <th>C#SELLERID()#35</th>\n",
       "      <th>C#SELLERID()#NONE</th>\n",
       "      <th>C#SHIPPINGCITY()#BARUERI</th>\n",
       "      <th>C#SHIPPINGCITY()#OSASCO</th>\n",
       "      <th>C#SHIPPINGCITY()#SANTANA_DE_PARNAIBA</th>\n",
       "      <th>C#SHIPPINGCITY()#SAO_PAULO</th>\n",
       "      <th>C#UTMSOURCELASTCLICK()#EMAIL</th>\n",
       "      <th>C#UTMSOURCELASTCLICK()#FACEBOOK</th>\n",
       "      <th>C#UTMSOURCELASTCLICK()#NA_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BUREAUBILLCITY()  BUREAUBILLSTATE()  BUREAUDOB()  BUREAUEMAIL()  \\\n",
       "0               0.0                0.0          0.0            0.0   \n",
       "1               0.0                0.0          0.0            0.0   \n",
       "2               0.0                0.0          0.0            0.0   \n",
       "3               0.0                0.0          0.0            0.0   \n",
       "4               0.0                0.0          0.0            0.0   \n",
       "\n",
       "   BUREAUPHONE()  BUREAUPHONEAREACODE()  BUREAUSHIPCITY()  BUREAUSHIPSTATE()  \\\n",
       "0            0.0                    0.0               0.0                0.0   \n",
       "1            0.0                    0.0               0.0                0.0   \n",
       "2            0.0                    0.0               0.0                0.0   \n",
       "3            0.0                    0.0               0.0                0.0   \n",
       "4            0.0                    0.0               0.0                0.0   \n",
       "\n",
       "   CREDITCARDCOUNTRYSAMEASBILLING()  CREDITCARDCOUNTRYSAMEASSHIPPING()  ...  \\\n",
       "0                               1.0                                1.0  ...   \n",
       "1                               1.0                                1.0  ...   \n",
       "2                               1.0                                1.0  ...   \n",
       "3                               1.0                                1.0  ...   \n",
       "4                               1.0                                1.0  ...   \n",
       "\n",
       "   C#SELLERID()#31  C#SELLERID()#35  C#SELLERID()#NONE  \\\n",
       "0                0                0                  1   \n",
       "1                0                0                  1   \n",
       "2                0                0                  1   \n",
       "3                0                0                  1   \n",
       "4                0                0                  1   \n",
       "\n",
       "   C#SHIPPINGCITY()#BARUERI  C#SHIPPINGCITY()#OSASCO  \\\n",
       "0                         0                        0   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         0                        0   \n",
       "4                         0                        0   \n",
       "\n",
       "   C#SHIPPINGCITY()#SANTANA_DE_PARNAIBA  C#SHIPPINGCITY()#SAO_PAULO  \\\n",
       "0                                     0                           1   \n",
       "1                                     0                           1   \n",
       "2                                     0                           1   \n",
       "3                                     0                           1   \n",
       "4                                     0                           1   \n",
       "\n",
       "   C#UTMSOURCELASTCLICK()#EMAIL  C#UTMSOURCELASTCLICK()#FACEBOOK  \\\n",
       "0                             0                                0   \n",
       "1                             0                                0   \n",
       "2                             0                                0   \n",
       "3                             0                                0   \n",
       "4                             0                                0   \n",
       "\n",
       "   C#UTMSOURCELASTCLICK()#NA_VALUE  \n",
       "0                                1  \n",
       "1                                1  \n",
       "2                                1  \n",
       "3                                1  \n",
       "4                                1  \n",
       "\n",
       "[5 rows x 2104 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scaled = pd.concat([df_train_scaled, dummies_train], axis=1)\n",
    "df_test_scaled = pd.concat([df_test_scaled, dummies_test], axis=1)\n",
    "\n",
    "print('\\033[1mShape of df_train_scaled for store ' + str(s) + ':\\033[0m ' + str(df_train_scaled.shape) + '.')\n",
    "print('\\033[1mShape of df_test_scaled for store ' + str(s) + ':\\033[0m ' + str(df_test_scaled.shape) + '.')\n",
    "print('\\n')\n",
    "\n",
    "df_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values (training data):\n",
    "num_miss_train = df_train_scaled.isnull().sum().sum() > 0\n",
    "if num_miss_train:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(df_train_scaled.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "\n",
    "# Assessing missing values (test data):\n",
    "num_miss_test = df_test_scaled.isnull().sum().sum() > 0\n",
    "if num_miss_test:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(df_test_scaled.isnull().sum().sum()) + '.')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='datasets_structure'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking consistency of structure between training and test dataframes:\n",
    "if len(list(df_train_scaled.columns)) != len(list(df_test_scaled.columns)):\n",
    "    print('\\033[1mProblem - Inconsistent number of columns between dataframes for training and test data!\\033[0m')\n",
    "\n",
    "else:\n",
    "    consistency_check = 0\n",
    "    \n",
    "    # Loop over variables:\n",
    "    for c in list(df_train_scaled.columns):\n",
    "        if list(df_train_scaled.columns).index(c) != list(df_test_scaled.columns).index(c):\n",
    "            print('\\033[1mProblem - Feature {0} was positioned differently in training and test dataframes!\\033[0m'.format(c))\n",
    "            consistency_check += 1\n",
    "            \n",
    "    # Reordering columns of test dataframe:\n",
    "    if consistency_check > 0:\n",
    "        ordered_columns = list(df_train_scaled.columns)\n",
    "        df_test_scaled = df_test_scaled[ordered_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_estimation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grids'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grids of hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare grid of hyper-parameters:\n",
    "if method == 'logistic_regression':\n",
    "    # Default values for hyper-parameters:\n",
    "    params_default = {'C': 1}\n",
    "\n",
    "    # Grid of values for hyper-parameters:\n",
    "    grid_regul = [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.25, 0.3, 0.5, 0.75, 1, 3, 10]\n",
    "\n",
    "    if random_search:\n",
    "        # Number of samples from each random distribution of regularization parameter:\n",
    "        n1 = int(n_samples*round(len([x for x in grid_regul if (x < 0.1)])/len(grid_regul), 2))\n",
    "        n2 = int(n_samples*round(len([x for x in grid_regul if (x >= 0.1) & (x < 1)])/len(grid_regul), 2)) + 1\n",
    "        n3 = int(n_samples*round(len([x for x in grid_regul if x >= 1])/len(grid_regul), 2))\n",
    "\n",
    "        grid_regul = []\n",
    "\n",
    "        # Loop over random distributions of regularization parameter:\n",
    "        for d in [uniform(0.0001, 0.1).rvs(n1), uniform(0.1, 1).rvs(n2), uniform(1, 10).rvs(n3)]:\n",
    "            for x in d:\n",
    "                grid_regul.append(x)\n",
    "    \n",
    "    params = {'C': grid_regul}\n",
    "\n",
    "elif method == 'GBM':\n",
    "    # Default values of hyper-parameters:\n",
    "    params_default = {'subsample': 0.75,\n",
    "                      'learning_rate': 0.01,\n",
    "                      'max_depth': 3,\n",
    "                      'n_estimators': 500}\n",
    "    \n",
    "    if random_search:\n",
    "        # Random distributions of hyper-parameters:\n",
    "        params = {'subsample': [0.75],\n",
    "                  'learning_rate': uniform(0.0001, 0.1),\n",
    "                  'max_depth': randint(1, 5+1),\n",
    "                  'n_estimators': randint(100, 500+1)}\n",
    "\n",
    "    else:\n",
    "        # Grid of values for hyper-parameters:\n",
    "        params = {'subsample': [0.75],\n",
    "                  'learning_rate': [0.0001, 0.01, 0.1],\n",
    "                  'max_depth': [1, 3, 5],\n",
    "                  'n_estimators': [100, 250, 500]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='estimations'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mGrid estimation progress:\u001b[0m [----------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mRunning time (K-folds CV estimation):\u001b[0m 0.4 minutes.\n",
      "Start time: 2020-12-31, 17:07:25\n",
      "End time: 2020-12-31, 17:07:50\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\u001b[1mK-folds CV outcomes:\u001b[0m\n",
      "Number of data folds: 3.\n",
      "Number of samples for random search: 10.\n",
      "Estimation method: logistic regression.\n",
      "Metric for choosing best hyper-parameter: roc_auc.\n",
      "Best hyper-parameters: {'C': 0.3}.\n",
      "CV performance metric associated with best hyper-parameters: 0.9081.\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------\n",
      "\u001b[1mPerformance metrics evaluated at test data:\u001b[0m\n",
      "test_roc_auc = 0.9639\n",
      "test_prec_avg = 0.7539\n",
      "test_brier = 0.0028\n",
      "--------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1mTotal rununning time:\u001b[0m 0.42 minutes.\n",
      "Start time: 2020-12-31, 17:07:25\n",
      "End time: 2020-12-31, 17:07:51\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare K-folds CV estimation object:\n",
    "train_test_est = Kfolds_fit(task = 'classification', method = method,\n",
    "                            metric = 'roc_auc', num_folds = 3,\n",
    "                            pre_selecting = False, pre_selecting_param = None,\n",
    "                            random_search = random_search, n_samples = n_samples,\n",
    "                            grid_param = params, default_param = params_default)\n",
    "\n",
    "# Running train-test estimation:\n",
    "train_test_est.run(train_inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                   train_output=df_train_scaled['y'],\n",
    "                   test_inputs=df_test_scaled.drop(drop_vars, axis=1),\n",
    "                   test_output=df_test_scaled['y'])\n",
    "\n",
    "# Defining best tuning hyper-parameter:\n",
    "best_params = train_test_est.best_param\n",
    "\n",
    "# Assessing performance metrics:\n",
    "test_roc_auc = train_test_est.performance_metrics[\"test_roc_auc\"]\n",
    "test_prec_avg = train_test_est.performance_metrics[\"test_prec_avg\"]\n",
    "test_brier = train_test_est.performance_metrics[\"test_brier\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assess_results'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "\n",
    "model_assessment[estimation_id] = {\n",
    "    'store_id': s,\n",
    "    'n_orders_train': len(df_train_scaled),\n",
    "    'n_orders_test': len(df_test_scaled),\n",
    "    'n_vars': df_train_scaled.drop(drop_vars, axis=1).shape[1],\n",
    "    'first_date_train': str(df_train_scaled.date.min().date()),\n",
    "    'last_date_train': str(df_train_scaled.date.max().date()),\n",
    "    'first_date_test': str(df_test_scaled.date.min().date()),\n",
    "    'last_date_test': str(df_test_scaled.date.max().date()),\n",
    "    'avg_order_amount_train': df_train_scaled.order_amount.mean(),\n",
    "    'avg_order_amount_test': df_test_scaled.order_amount.mean(),\n",
    "    'log_transform': log_transform,\n",
    "    'standardize': standardize,\n",
    "    'method': method,\n",
    "    'random_search': random_search,\n",
    "    'n_samples': n_samples,\n",
    "    'best_param': str(best_params),\n",
    "    'test_roc_auc': test_roc_auc,\n",
    "    'test_brier': test_prec_avg,\n",
    "    'test_prec_avg': test_brier,\n",
    "    'running_time': str(round((end_time - start_time).seconds/60 , 2)) + ' minutes'\n",
    "}\n",
    "\n",
    "if export:\n",
    "    with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "        json.dump(model_assessment, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

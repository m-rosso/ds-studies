{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Performance Metrics for Classification.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"DDxluGKrF97Z"},"source":["## Performance metrics for classification problems"]},{"cell_type":"markdown","metadata":{"id":"LWWQuaioF97o"},"source":["Classification problems bring several different concepts when it comes to assess the performance of a classifier. First of all, classification may be based either on *binary* or *multinomial* response variables. Although similar, these two settings of classification require attention when calculating metrics for evaluation. In addition to statistics suited for multinomial problems (for example, multinomial deviance), some metrics used for binary problems, such as precision, recall, and F1 score, should be calculated for each class separetely (see references for sources with detailed discussion on metrics for multiclass classification).\n","<br>\n","<br>\n","This notebook focus on performance metrics for binary classification, even though some ideas or results may also hold for multinomial problems. A *statistical learning method* is applied to estimate a model $f(.)$ referenced by *parameters* $\\theta$. These parameters determine how inputs $X$ define the output $Y$. When the response variable is binary, $Y \\in \\{0, 1\\}$, such as for the dataset used here, the estimation of $\\theta$ leads to the calculation of a *score* $P(y = 1|x, \\hat{\\theta})$ for a given data point $x$.\n","<br>\n","<br>\n","Metrics of performance for binary classification problems may either compare true labels with scores or true labels with predicted classes, where these follow from opposing scores with a predefined threshold to allocate data points to $Y = 1$ or to $Y = 0$. Not just that, some metrics may be explicitly dependent on the choice of a given threshold, or may consider several diffent thresholds, or even may not use any threshold at all. The approach here has separated metrics into those whose value consists on a rate and those that report some kind of score. The former class of metrics is prone to use a given threshold in its calculation.\n","<br>\n","<br>\n","Two relevant subjects concerning classification point to *class imbalance* and *domain knowledge*. A given dataset is imbalanced when the prior probability of some class, $P(Y = 1)$ for binary problems, is too low or too high. This should raise special care when applying and interpreting any performance metric. Domaing knowledge is also crucial, since different costs may follow from different sorts of misclassification, even when there are only two possible classes."]},{"cell_type":"markdown","metadata":{"id":"HEY1o4zlKLO_"},"source":["---------------------"]},{"cell_type":"markdown","metadata":{"id":"9qaB_0r-KK7t"},"source":["This notebook presents the definition and practical implementations of main metrics for classification tasks. The data used for the examples follows from Kaggle repository of datasets, and consists of a dataset for the construction of a classification algorithm for the [identification of malware apps](https://www.kaggle.com/saurabhshahane/android-permission-dataset), although only true labels and predicted scores are used here. The notebook is organized as follows: after the importing of libraries and the data, two distinct collections of metrics are approached: those that are calculated as rates comparing true and predicted labels, and, after that, those metrics which oppose predicted probabilities to the true labels. Some of the references for this study are present by the end of the notebook."]},{"cell_type":"markdown","metadata":{"id":"CMospJM6F97t"},"source":["**Summary:**\n","1. [Libraries](#libraries)<a href='#libraries'></a>.\n","2. [Importing datasets](#imports)<a href='#imports'></a>.\n","3. [Rate metrics](#rate)<a href='#rate'> </a>.\n","    * [Confusion matrix](#conf_matrix)<a href='#conf_matrix'></a>.\n","    * [Rates from confusion matrix](#rates_conf_matrix)<a href='#rates_conf_matrix'></a>\n","\n","\n","4. [Score metrics](#score)<a href='#score'></a>.\n","    * [ROC curve](#roc)<a href='#roc'></a>.\n","    * [Precision-recall](#precision_recall)<a href='#precision_recall'></a>.\n","    * [F1 score](#F1)<a href='#F1'></a>.\n","    * [G-mean](#g_mean)<a href='#g_mean'></a>.\n","    * [Matthews correlation coefficient (MCC)](#mcc)<a href='#mcc'></a>.\n","    * [Brier score](#brier_score)<a href='#brier_score'></a>.\n","    * [Binomial deviance](#binomial_deviance)<a href='#binomial_deviance'></a>.\n","    * [Multinomial deviance](#multinomial_deviance)<a href='#multinomial_deviance'></a>.\n","\n","\n","5. [References](#references)<a href='#references'></a>."]},{"cell_type":"markdown","metadata":{"id":"yKZ4tvaaF97x"},"source":["<a id='libraries'> </a>"]},{"cell_type":"markdown","metadata":{"id":"UF04KTH6F972"},"source":["## Libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3izVpGyvGB2l","executionInfo":{"status":"ok","timestamp":1632601546486,"user_tz":180,"elapsed":575,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"616f71e6-4865-4ad8-811c-b7d0f49a262d"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GDx7hxnCGmzF","executionInfo":{"status":"ok","timestamp":1632601546866,"user_tz":180,"elapsed":31,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"91c72119-040f-4a4e-82a8-434b4cc4487e"},"source":["cd \"/content/gdrive/MyDrive/Studies/Performance Metrics for Classification/Codes\""],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Studies/Performance Metrics for Classification/Codes\n"]}]},{"cell_type":"code","metadata":{"id":"uIz3UGuZF974","executionInfo":{"status":"ok","timestamp":1632601547249,"user_tz":180,"elapsed":396,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}}},"source":["import pandas as pd\n","import numpy as np\n","\n","import os\n","import json\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.metrics import f1_score, matthews_corrcoef\n","from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n","from sklearn.metrics import auc, roc_curve, precision_recall_curve"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rLof-wbOF97-"},"source":["<a id='imports'> </a>"]},{"cell_type":"markdown","metadata":{"id":"ZtnWm9VnF98A"},"source":["## Importing data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"VJ3u-CkiG3zL","executionInfo":{"status":"ok","timestamp":1632601547254,"user_tz":180,"elapsed":120,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"bc54deda-79a7-47f9-caa5-fa4870a35bd3"},"source":["# True labels (binary classification task) and predicted scores:\n","scores = pd.read_csv('../Datasets/test_scores.csv')\n","print(f'Shape of scores: {scores.shape}.')\n","\n","scores.head(3)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of scores: (6827, 3).\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>y_pred</th>\n","      <th>y_true</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.988038</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.394664</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.053502</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id    y_pred  y_true\n","0   1  0.988038       1\n","1   2  0.394664       0\n","2   3  0.053502       0"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"GxVFqIVMF98I"},"source":["<a id='rate'> </a>"]},{"cell_type":"markdown","metadata":{"id":"CZK_cOgaF98J"},"source":["## Rate metrics"]},{"cell_type":"markdown","metadata":{"id":"JZIMAfL6F98L"},"source":["This first kind of metrics for classification performance requires the definition of a *threshold* above which an estimated probability of $Y = 1$ points to predicting $\\hat{Y} = 1$, and below which an estimated probability indicates $\\hat{Y} = 0$. Although these metrics are more precise to assess how good a model is to accomplish its classification task, they rely on the definition of a threshold parameter, which is particularly tricky when the binary response variable is highly imbalanced, since $0.5$ is inappropriate in such contexts where the prior rate for $Y = 1$ is too lower or too higher than that value."]},{"cell_type":"code","metadata":{"id":"K3KJB9h4F98M","executionInfo":{"status":"ok","timestamp":1632601547257,"user_tz":180,"elapsed":106,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}}},"source":["# Function for predicting class from estimated probability:\n","def class_pred(x, threshold=0.5):\n","    if x > threshold:\n","        return 1\n","    else:\n","        return 0"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"UaBFUFhrF98P","executionInfo":{"status":"ok","timestamp":1632601547262,"user_tz":180,"elapsed":109,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}}},"source":["# Predicting classes:\n","thres = 0.5\n","scores['class_pred'] = scores['y_pred'].apply(class_pred, threshold=thres)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dVYYNrFuF98T"},"source":["<a id='conf_matrix'> </a>"]},{"cell_type":"markdown","metadata":{"id":"AcxO6bXzF98T"},"source":["### Confusion matrix"]},{"cell_type":"markdown","metadata":{"id":"hJ5eRgZ7F98V"},"source":["In binary classification problems, with a response variable $Y \\in \\{0, 1\\}$, there are two kinds of errors when predicting the label for $Y$: **false negative (type-II error)**, that occurs when $\\hat{Y} = 0$ and $Y = 1$, and **false positive (type-I error)**, that holds when $\\hat{Y} = 1$ and $Y = 0$. Analogously, there are also two kinds of correct predictions: **true negative**, when $Y = \\hat{Y} = 0$, and **true positive**, when $Y = \\hat{Y} = 1$. Confusion matrix, that actually applies similarly to multiclass classification problems, summarizes all possible events when predicting labels from a given dataset.\n","<br>\n","<br>\n","Not only the threshold should be chosen carefully when rate metrics are used to assess classification performance, but also which metric to focused on, since false negatives may produce more damage than false positives in some contexts, and vice-versa."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"PcWureqCF98W","executionInfo":{"status":"ok","timestamp":1632601547274,"user_tz":180,"elapsed":119,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"2e5a99a2-03f0-42b9-d95d-50799eaf3850"},"source":["# Confusion matrix implementation:\n","conf_matrix = pd.DataFrame(data=confusion_matrix(scores['y_true'], scores['class_pred']))\n","conf_matrix.index.name = 'y_true'\n","conf_matrix.columns.name = 'y_pred'\n","\n","print(f'\\033[1mThreshold:\\033[0m {thres}.')\n","conf_matrix"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mThreshold:\u001b[0m 0.5.\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>y_pred</th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","    <tr>\n","      <th>y_true</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1880</td>\n","      <td>384</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>819</td>\n","      <td>3744</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["y_pred     0     1\n","y_true            \n","0       1880   384\n","1        819  3744"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsrvh4B0F98X","executionInfo":{"status":"ok","timestamp":1632601547277,"user_tz":180,"elapsed":109,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"f27ef1f2-321f-4067-e26a-cbc8b274a480"},"source":["# False negatives:\n","FN = conf_matrix.iloc[1,0]\n","print(f'\\033[1mFalse negatives (y_pred = 0 and y_true = 1)\\033[0m: {FN}.')"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mFalse negatives (y_pred = 0 and y_true = 1)\u001b[0m: 819.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OE1vbSJ6F98Z","executionInfo":{"status":"ok","timestamp":1632601547283,"user_tz":180,"elapsed":106,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"52deae32-00eb-44ca-b342-e077856225b4"},"source":["# True negatives:\n","TN = conf_matrix.iloc[0,0]\n","print(f'\\033[1mTrue negatives (y_pred = 0 and y_true = 0)\\033[0m: {TN}.')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mTrue negatives (y_pred = 0 and y_true = 0)\u001b[0m: 1880.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFZfnklTF98a","executionInfo":{"status":"ok","timestamp":1632601547286,"user_tz":180,"elapsed":96,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"d824be9a-9279-4fdc-d4d9-a1993ade54eb"},"source":["# False positives:\n","FP = conf_matrix.iloc[0,1]\n","print(f'\\033[1mFalse positives (y_pred = 1 and y_true = 0)\\033[0m: {FP}.')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mFalse positives (y_pred = 1 and y_true = 0)\u001b[0m: 384.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7JfFfGZ-F98b","executionInfo":{"status":"ok","timestamp":1632601547938,"user_tz":180,"elapsed":165,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"44f71ffb-9a18-4af3-f77c-98585cbf08e7"},"source":["# True positives:\n","TP = conf_matrix.iloc[1,1]\n","print(f'\\033[1mTrue positives (y_pred = 1 and y_true = 1)\\033[0m: {TP}.')"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mTrue positives (y_pred = 1 and y_true = 1)\u001b[0m: 3744.\n"]}]},{"cell_type":"markdown","metadata":{"id":"KgG4bztsF98e"},"source":["<a id='rates_conf_matrix'> </a>"]},{"cell_type":"markdown","metadata":{"id":"gr44Jlr0F982"},"source":["### Rates from confusion matrix"]},{"cell_type":"markdown","metadata":{"id":"81yX04OzF983"},"source":["#### False negative rate (*miss rate*)"]},{"cell_type":"markdown","metadata":{"id":"glTKOsNtF984"},"source":["The **false negative rate** is given by the ratio between false negatives and positives:\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle fnr = \\frac{FN}{P} = \\frac{FN}{(FN + TP)}\n","\\end{equation}"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Oyh94U0F985","executionInfo":{"status":"ok","timestamp":1632601547940,"user_tz":180,"elapsed":146,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"ab19df80-dd80-4256-9f54-7b5937eb5a33"},"source":["fnr = FN/(FN + TP)\n","print(f'\\033[1mFalse negative rate (miss rate):\\033[0m {round((fnr*100), 2)}%.')"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mFalse negative rate (miss rate):\u001b[0m 17.95%.\n"]}]},{"cell_type":"markdown","metadata":{"id":"FD0HXHfCF987"},"source":["#### False positive rate (*fall out*)"]},{"cell_type":"markdown","metadata":{"id":"feqBDTCGF99G"},"source":["Similarly, the **false positive rate** is given by the ratio between false positives and negatives:\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle fpr = \\frac{FP}{N} = \\frac{FP}{(FP + TN)}\n","\\end{equation}"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXFergoXF99H","executionInfo":{"status":"ok","timestamp":1632601547942,"user_tz":180,"elapsed":134,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"0cefcd6a-3b2e-4cd4-e53e-2e84863a2d64"},"source":["fpr = FP/(FP + TN)\n","print(f'\\033[1mFalse positive rate (fall out):\\033[0m {round((fpr*100), 2)}%.')"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mFalse positive rate (fall out):\u001b[0m 16.96%.\n"]}]},{"cell_type":"markdown","metadata":{"id":"osaDK_s4F99J"},"source":["#### Positive predictive value (*precision*)"]},{"cell_type":"markdown","metadata":{"id":"b5St5llEF99J"},"source":["The **positive predictive value**, also known as **precision**, is based on the total number of positive predictions $\\hat{Y} = 1$. Then, it is given by the ratio between true positives and predicted positives:\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle precision = \\frac{TP}{\\hat{P}} = \\frac{TP}{(FP + TP)}\n","\\end{equation}"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECxxemR2F99K","executionInfo":{"status":"ok","timestamp":1632601547943,"user_tz":180,"elapsed":121,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"1efe015b-4bd2-4aac-f521-dfe73fa07222"},"source":["prec = TP/(FP + TP)\n","print(f'\\033[1mPositive predictive value (precision):\\033[0m {round((prec*100), 2)}%.')"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mPositive predictive value (precision):\u001b[0m 90.7%.\n"]}]},{"cell_type":"markdown","metadata":{"id":"cxdBWfqBF99N"},"source":["#### Sensitivity (*recall*, or *true positive rate*)"]},{"cell_type":"markdown","metadata":{"id":"BMV_faJiF99Q"},"source":["The **true positive rate**, also defined as **recall** or **sensitivity**, focus on true positives, but has actual positives as the reference:\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle recall = \\frac{TP}{P} = \\frac{TP}{(FN + TP)}\n","\\end{equation}"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QSF55Eh6F99S","executionInfo":{"status":"ok","timestamp":1632601547945,"user_tz":180,"elapsed":109,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"ea84463d-aadd-42aa-dc96-ac9af4d572fc"},"source":["rec = TP/(FN + TP)\n","print(f'\\033[1mSensitivity (recall, or true positive rate):\\033[0m {round((rec*100), 2)}%.')"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mSensitivity (recall, or true positive rate):\u001b[0m 82.05%.\n"]}]},{"cell_type":"markdown","metadata":{"id":"O0hYcTAkF99U"},"source":["#### Negative predictive value"]},{"cell_type":"markdown","metadata":{"id":"Ed7bD0TMF99V"},"source":["The **negative predictive value** is analogous to precision, but focused on true negatives:\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle neg\\_pred = \\frac{TN}{\\hat{N}} = \\frac{TN}{(FN + TN)}\n","\\end{equation}"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GdkX0d0WF99W","executionInfo":{"status":"ok","timestamp":1632601547947,"user_tz":180,"elapsed":100,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"38b45f97-6db7-4b44-afea-ad4167eb1392"},"source":["neg_pred = TN/(FN + TN)\n","print(f'\\033[1mNegative predictive value:\\033[0m {round((neg_pred*100), 2)}%.')"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mNegative predictive value:\u001b[0m 69.66%.\n"]}]},{"cell_type":"markdown","metadata":{"id":"nbCJL55-F99X"},"source":["#### Specificity (*true negative rate*)"]},{"cell_type":"markdown","metadata":{"id":"8fP4ReGhF99Y"},"source":["The **specificity**, or **true negative rate** is similar to negative predictive value, but having as reference actual negatives instead of predicted negatives. Besides, is given by the complement to false positive rate (fall out):\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle specificity = \\frac{TN}{N} = \\frac{TN}{(FP + TN)}\n","\\end{equation}"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4u3bLiiqF99Z","executionInfo":{"status":"ok","timestamp":1632601547949,"user_tz":180,"elapsed":91,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"ea35a942-9e4c-495d-ab30-dfa98b8c5ce5"},"source":["tnr = TN/(FP + TN)\n","print(f'\\033[1mSpecificity (true negative rate):\\033[0m {round((tnr*100), 2)}%.')"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mSpecificity (true negative rate):\u001b[0m 83.04%.\n"]}]},{"cell_type":"markdown","metadata":{"id":"NjYM9OApF99a"},"source":["#### False discovery rate"]},{"cell_type":"markdown","metadata":{"id":"xz8grYYVF99b"},"source":["The **false discovery rate** is analogous to precision, but focused on false positives instead of true positives:\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle false\\_disc = \\frac{FP}{\\hat{P}} = \\frac{TP}{(FP + TP)}\n","\\end{equation}"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cvU2uluxF99d","executionInfo":{"status":"ok","timestamp":1632601547954,"user_tz":180,"elapsed":84,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"c81c6079-5d73-445c-ea8d-4366ed78d63c"},"source":["false_disc = FP/(FP + TP)\n","print(f'\\033[1mFalse discovery rate:\\033[0m {round((false_disc*100), 2)}%.')"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mFalse discovery rate:\u001b[0m 9.3%.\n"]}]},{"cell_type":"markdown","metadata":{"id":"A9LzuXWtF99e"},"source":["#### Error rate"]},{"cell_type":"markdown","metadata":{"id":"6HqqDv8OF99e"},"source":["The **error rate** consists on a loss function to be minimized when estimating a classification model, since it aggregates all possible errors when classifying a binary response variable (even though it also applies for multiclass classification problems). Therefore, this rate is given by dividing the sum of false negatives and false positives by the number of observations:\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle err = \\frac{(FN + FP)}{(FN + TN + FP + TP)}\n","\\end{equation}"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PyCnEeY9F99f","executionInfo":{"status":"ok","timestamp":1632601547957,"user_tz":180,"elapsed":74,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"cbc579f8-018b-4ee4-866a-b4d2d7140e10"},"source":["err = (FN + FP)/(FN + TN + FP + TP)\n","print(f'\\033[1mError rate:\\033[0m {round((err*100), 2)}%.')"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mError rate:\u001b[0m 17.62%.\n"]}]},{"cell_type":"markdown","metadata":{"id":"LcAKYaC-F99i"},"source":["<a id='score'> </a>"]},{"cell_type":"markdown","metadata":{"id":"w4Y9oy6eF99j"},"source":["## Score metrics"]},{"cell_type":"markdown","metadata":{"id":"tB6HG9-DF99k"},"source":["There is a type of metrics for classification performance that does not depend on the choice of threshold, which is particularly useful for comparing different classifiers. Moreover, these metrics reveal more clearly how good is the performance of a classifier, since they condensate information into a single statistic. Basically, they can be divided into two subtypes:\n","1. Those combining rates from confusion matrix ([ROC](#roc)<a href='#roc'></a>, [precision-recall](#roc)<a href='#roc'></a> curves, [F1 score](#F1)<a href='#F1'></a>, [G-mean](#g_mean)<a href='#g_mean'></a>, [MCC](#mcc)<a href='#mcc'></a>).\n","2. Those consisting on loss functions for classification ([Brier score](#brier_score)<a href='#brier_score'></a>, [deviance](#binomial_deviance)<a href='#binomial_deviance'></a>)."]},{"cell_type":"markdown","metadata":{"id":"AmSx8TPpF99k"},"source":["<a id='roc'> </a>"]},{"cell_type":"markdown","metadata":{"id":"2gVsDDFUF99o"},"source":["### ROC curve"]},{"cell_type":"markdown","metadata":{"id":"6cYjURR0F99p"},"source":["ROC stands for **Receiver Operating Characteristic**, and explores the fact that rates such as false positive rate ($fpr = FP/N = FP/(FP + TN)$) and true positive rate ($tpr = TP/(FN + TP)$) are defined as a function of the threshold that assigns each data point to a class, given its estimated score.\n","<br>\n","<br>\n","The construction of a ROC curve involves calculating $fpr$ and $tpr$ for several different threshold, then plotting each $fpr$-$tpr$ pair in a plot where the x-axis receives the $fpr$ value, while the y-axis denotes the $tpr$ value. Consequently, a classifier with good performance has its ROC curve located near to the top-left corner of the plot, suggesting the existence of thresholds for which the $fpr$ is very low (and $tnr$ is very high) - left portion - and the $tpr$ is very high (and $fnr$ is very low) - top portion.\n","<br>\n","<br>\n","The baseline for ROC curve is given by the line for which $tpr = fpr$, reflecting a classifier that has as many chances of correctly predicting $Y = 1$ as of wrongly guessing positives. When the classes are balanced, such classifier is equivalent to random guessing."]},{"cell_type":"markdown","metadata":{"id":"SNfToFIUF99r"},"source":["#### ROC curve"]},{"cell_type":"code","metadata":{"id":"gBat5xXVF99v","executionInfo":{"status":"ok","timestamp":1632601547958,"user_tz":180,"elapsed":59,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}}},"source":["# Implementation with sklearn:\n","fpr, tpr, threshold = roc_curve(scores['y_true'], scores['y_pred'])\n","auc_roc = auc(fpr, tpr)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"-vMxG7itF99x","executionInfo":{"status":"ok","timestamp":1632601564716,"user_tz":180,"elapsed":16813,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"d538afca-1592-4bc4-b3b3-ef05047e9c8b"},"source":["plt.figure(figsize=(6,4))\n","\n","sns.lineplot(fpr, tpr)\n","plt.plot(np.linspace(0, 1, 1000), np.linspace(0, 1, 1000), '--', linewidth=1, color='black')\n","\n","plt.xlabel('False positive rate')\n","plt.ylabel('True positive rate')\n","plt.title('ROC curve')\n","plt.text(0.82, 0.08, 'AUC = ' + str(round(auc_roc, 4)), fontsize=10, verticalalignment='top')\n","\n","plt.tight_layout()"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"jgd9m6IFF99y"},"source":["#### ROC-AUC score"]},{"cell_type":"markdown","metadata":{"id":"wRLdZqVOF99z"},"source":["The performance information provided by a given ROC curve is summarized through the area under the curve (AUC). The higher its value, the nearer the curve is to the top-left corner of the plot, thus suggesting a good classification performance. When it comes to comparing different classifiers, each referenced by $\\theta_m$, the best model among them is that with the highest ROC-AUC value."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFDQpmqmF990","executionInfo":{"status":"ok","timestamp":1632601564719,"user_tz":180,"elapsed":70,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"0d30b26a-5448-415b-a1a7-e3f75be3577b"},"source":["# Direct implementation with sklearn:\n","roc_auc_score(scores['y_true'], scores['y_pred'])"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9137064895932795"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e48EUkxoF992","executionInfo":{"status":"ok","timestamp":1632601564721,"user_tz":180,"elapsed":56,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"e703f444-ab67-43d9-9ad6-9fb5f77aa2bd"},"source":["# Indirect implementation:\n","auc(fpr, tpr)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9137064895932795"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"KUVUFc6tF993"},"source":["<a id='precision_recall'> </a>"]},{"cell_type":"markdown","metadata":{"id":"y-QmTUnhF994"},"source":["### Precision-recall curve"]},{"cell_type":"markdown","metadata":{"id":"8JcJmgGGF995"},"source":["**Precision** is given by the positive predictive value $TP/\\hat{P} = TP/(FP + TP)$, while **recall** is equal to the true positive rate, i.e., the sensitivity $TP/P = TP/(FN + TP)$. Thus, the reference is what differences precision from recall, where the first is constructed relatively from the predictions of label $\\hat{Y} = 1$ and the second is based on the number of actual positives $Y = 1$. Both precision and recall should be maximized by a classifier.\n","<br>\n","<br>\n","Precision and recall focus mainly in the correct prediction of label $Y = 1$, and therefore is relevant for contexts where there is a high imbalance between the classes of a binary response variable $Y$.\n","<br>\n","<br>\n","Since $FP$, $TP$, $FN$ and $TN$ are all entities defined by comparing a score with a given threshold, both precision and recall vary across different values for the threshold. Consequently, it is possible to plot precision-recall pairs for different thresholds, and this gives rise to the **precision-recall curve**. Such a plot has the x-axis given by recall and y-axis by precision.\n","<br>\n","<br>\n","The baseline for precision-recall curve is a horizontal line centered in the value of $P/(P + N)$, and the farthest the curve is to the baseline the better will be the classification model, revealing that the classifier has ability to distinguish between classes, being preferred to the random guess or the constant prediction. Irrespective of the baseline, the perfect scenario is to have a precision-recall curve touching the top-right extreme $(1, 1)$, revealing that there is one threshold for which perfect prediction of label $Y = 1$ is possible.\n","<br>\n","<br>\n","**Note:** since the ROC-AUC statistic uses $fpr$ (the inverse of $tnr$) in its calculation, precision-recall may be preferred to it when the data is highly imbalanced."]},{"cell_type":"markdown","metadata":{"id":"aIAOtbtZF9-C"},"source":["#### Average precision score"]},{"cell_type":"markdown","metadata":{"id":"5rSTJksQF9-D"},"source":["Precision-recall curve is very convenient to fastly assess a classification performance. However, in order to compare different classifiers, it would be preferred to summarize mathematically a given precision-recall curve. The **average precision score** is a weighted mean for precision where the weights are given by the change in recall from a threshold $t-1$ to another threshold $t$:\n","\\begin{equation}\n","AP = \\sum_{t=1}^T(recall_t - recall_{t-1})precision_t\n","\\end{equation}\n","From this expression, a classifier referenced by $\\theta_m$ is better than another constructed upon a parameter vector $\\theta_{m'}$ if its average precision score is higher."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6uRnhm_fF9-E","executionInfo":{"status":"ok","timestamp":1632601564723,"user_tz":180,"elapsed":48,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"0d8bce8f-8cbb-403b-c17a-ce7b646f7506"},"source":["# Implementation with sklearn:\n","avg_prec = average_precision_score(scores['y_true'], scores['y_pred'])\n","print(avg_prec)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["0.960724643422885\n"]}]},{"cell_type":"markdown","metadata":{"id":"_iYOCBGQF9-F"},"source":["#### Precision-recall AUC score"]},{"cell_type":"markdown","metadata":{"id":"g6vzsqOpF9-G"},"source":["Another way of summarizing the information provided by a precision-recall curve is to compute the **area under the curve**, where the higher it is the better, since the closer the curve will be to the top-right corner of the plot.\n","<br>\n","<br>\n","**Note:** although very similiar, precision-recall AUC and average precision score may be different."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M41vFYwxF9-H","executionInfo":{"status":"ok","timestamp":1632601564724,"user_tz":180,"elapsed":39,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"26e78465-ca9d-40dd-b46a-f4313c07b08f"},"source":["# Implementation with sklearn:\n","precision, recall, threshold = precision_recall_curve(scores['y_true'], scores['y_pred'])\n","auc_prec_rec = auc(recall, precision)\n","ref_line = sum(scores.y_true==1)/len(scores.y_true)\n","print('\\033[1mArea under the curve:\\033[0m ' + str(round(auc_prec_rec, 4)) + '.')\n","print('\\033[1mBaseline:\\033[0m ' + str(round(ref_line, 4)) + '.')"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mArea under the curve:\u001b[0m 0.9607.\n","\u001b[1mBaseline:\u001b[0m 0.6684.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"ArSAmrcyF9-I","executionInfo":{"status":"ok","timestamp":1632601582333,"user_tz":180,"elapsed":17635,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"0f5d850d-3db9-44bd-eff7-cadd9a85aa6b"},"source":["# Precision-recall curve:\n","plt.figure(figsize=(6,4))\n","\n","sns.lineplot(x = recall, y = precision)\n","\n","plt.axhline(ref_line, color='black', ls='--', linewidth=1)\n","\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-recall curve')\n","plt.text(0.85, 1, 'AUC = ' + str(round(auc_prec_rec, 4)), fontsize=10, verticalalignment='top')\n","plt.text(0.85, 0.95, 'AP = ' + str(round(avg_prec, 4)), fontsize=10, verticalalignment='top')\n","\n","plt.tight_layout()"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"hqcUJ2ISF9-J"},"source":["<a id='F1'> </a>"]},{"cell_type":"markdown","metadata":{"id":"VSt87uYMF9-K"},"source":["### F1 score"]},{"cell_type":"markdown","metadata":{"id":"ozAi6TyeF9-L"},"source":["The **F1 score** is another metric based on precision and recall. Conventionally, its defined as the harmonic average of precision and recall, thus given by:\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle F1 = \\frac{2}{precision^{-1} + recall^{-1}} = 2*\\frac{precision*recall}{precision + recall}\n","\\end{equation}\n","<br>\n","<br>\n","Another definition takes a weight $\\beta$ for how many times recall is considered as important as precision:\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle F1 = (1 + \\beta^2)\\frac{precision*recall}{(\\beta^2)*precision + recall}\n","\\end{equation}\n","<br>\n","<br>\n","For binary classification problems, main F1 score calculation is as above, while for multiclass classification settings there are mainly three ways to calculate F1: macro-F1, weighted-F1, and micro-F1. *Macro-F1* and *weighted-F1* calculate one F1 score for each class, then averaging all of them through simple average (macro-F1) or using weighted average (weighted-F1), where this weighted average takes the positives of each class as weights. *Micro-F1*, for multiclass classification problems, is given by aggregate true positives divided by aggregate positives, therefore, it is equal to accuracy (1 - error rate). It is worth to notice that micro-F1 for binary classification problems is also equal to accuracy."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XtXRap7aF9-M","executionInfo":{"status":"ok","timestamp":1632601582335,"user_tz":180,"elapsed":113,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"b6ab4e8e-06a1-4687-8017-07fdd933e5d0"},"source":["# Manual implementation:\n","print(f'\\033[1mBinary F1 score:\\033[0m {(2*(prec*rec)/(prec + rec)):.4f}.')"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mBinary F1 score:\u001b[0m 0.8616.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODgBI5RLF9-N","executionInfo":{"status":"ok","timestamp":1632601582337,"user_tz":180,"elapsed":103,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"c31e364e-1abd-44d4-8d19-9e17ae3185b3"},"source":["# Implementation with sklearn:\n","print(f'\\033[1mBinary F1 score:\\033[0m {f1_score(scores[\"y_true\"], scores[\"class_pred\"]):.4f}.')\n","print(f'\\033[1mMacro-F1 score:\\033[0m {f1_score(scores[\"y_true\"], scores[\"class_pred\"], average=\"macro\"):.4f}.')\n","print(f'\\033[1mWeighted-F1 score:\\033[0m {f1_score(scores[\"y_true\"], scores[\"class_pred\"], average=\"weighted\"):.4f}.')\n","print(f'\\033[1mMicro-F1 score:\\033[0m {f1_score(scores[\"y_true\"], scores[\"class_pred\"], average=\"micro\"):.4f}.')"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mBinary F1 score:\u001b[0m 0.8616.\n","\u001b[1mMacro-F1 score:\u001b[0m 0.8096.\n","\u001b[1mWeighted-F1 score:\u001b[0m 0.8271.\n","\u001b[1mMicro-F1 score:\u001b[0m 0.8238.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrdBopfYF9-S","executionInfo":{"status":"ok","timestamp":1632601582338,"user_tz":180,"elapsed":94,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"6817fe6b-18fc-4195-a8ce-af8352a41671"},"source":["print(f'\\033[1mMicro-F1 score for binary problems (1 - err):\\033[0m {(1 - err):.4f}.')"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mMicro-F1 score for binary problems (1 - err):\u001b[0m 0.8238.\n"]}]},{"cell_type":"markdown","metadata":{"id":"IHLyYJAGXbu8"},"source":["<a id='g_mean'></a>"]},{"cell_type":"markdown","metadata":{"id":"Ezr5ijsIXd7v"},"source":["### G-mean"]},{"cell_type":"markdown","metadata":{"id":"EvrJO_ECXgF8"},"source":["**G-mean** stands for *geometric mean* and is given by the root square of the product between precision and recall. Consequently, it resembles F1 in the search for adequately weighting both precision and recall.\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle g\\_mean = \\sqrt{precision*recall}\n","\\end{equation}"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9o2h6ZDOYELn","executionInfo":{"status":"ok","timestamp":1632601582340,"user_tz":180,"elapsed":86,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"1334190b-2fde-48ce-9608-7310697e93c6"},"source":["print(f'\\033[1mg-mean:\\033[0m {np.sqrt(prec*rec):.4f}.')"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mg-mean:\u001b[0m 0.8627.\n"]}]},{"cell_type":"markdown","metadata":{"id":"_IebqsuDTrJ0"},"source":["<a id='mcc'> </a>"]},{"cell_type":"markdown","metadata":{"id":"mHjigNbtTxsm"},"source":["### Matthews correlation coefficient (MCC)"]},{"cell_type":"markdown","metadata":{"id":"fAhoLaIyUZsW"},"source":["Matthews correlation coefficient, known as **MCC**, is another performance metrics for binary classification that is derived directly from a confusion matrix. Its mathematical formulation involves all definitions: true and false positives, true and false negatives:\n","<br>\n","<br>\n","\\begin{equation}\n","\\displaystyle MCC = \\frac{TP*TN - FP*FN}{\\sqrt{(TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)}} = \\frac{TP*TN - FP*FN}{\\sqrt{\\hat{P}*P*N*\\hat{N}}} \\in [-1, 1]\n","\\end{equation}\n","<br>\n","<br>\n","As the name indicates, the MCC metric calculates the correlation between two random variables: true and predicted labels. Therefore, as any other correlation, this metric assumes values in the interval [-1, 1]: the closer to 1, the better the classification achieved by the trained model. Even that -1 seems the worst case scenario, it actually would lead to the opposite of a perfect classifier, since perfect accuracy could be obtained by reversing the classification suggested by the model. So, the closer a classifier gets to 0, the worse it is.\n","\n","A great advantage of MCC is that it covers outcomes related to both classes, so it is not asymmetric as accuracy, precision, recall and F1, and may also help with imbalanced classes."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AfyX3uuHTuRb","executionInfo":{"status":"ok","timestamp":1632601582341,"user_tz":180,"elapsed":78,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"5bc4a6c6-ce7b-4ab0-b07a-bae7d89b1e51"},"source":["print(f'\\033[1mMCC:\\033[0m {matthews_corrcoef(scores[\"y_true\"], scores[\"class_pred\"]):.4f}.')"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mMCC:\u001b[0m 0.6268.\n"]}]},{"cell_type":"markdown","metadata":{"id":"9_Eu9WhwF9-U"},"source":["<a id='brier_score'> </a>"]},{"cell_type":"markdown","metadata":{"id":"O9N08p1ZF9-V"},"source":["### Brier score"]},{"cell_type":"markdown","metadata":{"id":"CrJ00yzRF9-W"},"source":["Despite of its name, the **Brier score** can be seen as just the mean of squared-error loss function, more commonly used for regression problems. Thus, for a binary response variable $Y$, and considering a probability prediction $f(x_i; \\theta)$ for data point $x_i$, the Brier score is defined by:\n","\\begin{equation}\n","Brier(\\theta) = \\frac{1}{N}\\sum_{i=1}^N [y_i - f(x_i; \\theta)]^2\n","\\end{equation}\n","<br>\n","In a given estimation of $\\theta$, the smaller the Brier score, the better the estimation will be."]},{"cell_type":"markdown","metadata":{"id":"jEP10zVWF9-X"},"source":["#### Implementation"]},{"cell_type":"code","metadata":{"id":"NKpx6OCaF9-Y","executionInfo":{"status":"ok","timestamp":1632601582343,"user_tz":180,"elapsed":70,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}}},"source":["# Function that calculates squared-error for a set of data points:\n","def brier(y, p):\n","    \"y is a true binary label, while p is an estimated probability for reference class.\"\n","    return (1/len(y))*np.sum(np.square(y - p))"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JTnGhgCjF9-Z","executionInfo":{"status":"ok","timestamp":1632601582344,"user_tz":180,"elapsed":69,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"dac922cf-0cb2-44c4-e65b-aca2a1f6f61c"},"source":["# Manual implementation:\n","print(f'\\033[1mBrier score:\\033[0m {brier(scores[\"y_true\"], scores[\"y_pred\"]):.4f}.')"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mBrier score:\u001b[0m 0.1132.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5xQfEVOMF9-b","executionInfo":{"status":"ok","timestamp":1632601582346,"user_tz":180,"elapsed":58,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"28a80643-ca4d-4bab-ec31-fbfd8a9cf3d4"},"source":["# Implementation with sklearn:\n","print(f'\\033[1mBrier score:\\033[0m {brier_score_loss(scores[\"y_true\"], scores[\"y_pred\"]):.4f}.')"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mBrier score:\u001b[0m 0.1132.\n"]}]},{"cell_type":"markdown","metadata":{"id":"jBk433cyF9-e"},"source":["<a id='binomial_deviance'> </a>"]},{"cell_type":"markdown","metadata":{"id":"wnSUeBViF9-f"},"source":["### Binomial deviance"]},{"cell_type":"markdown","metadata":{"id":"LsYzCBtmF9-g"},"source":["Consists on a common loss function to be minimized when estimating statistical learning methods for binary classification problems. Given a probability prediction $f(x_i; \\theta)$ constructed from inputs $x_i$ and parameters $\\theta$, the following equation shows the expression for the **binomial deviance**:\n","\\begin{equation}\n","L(\\theta) = \\sum_{i=1}^N\\log\\{1 + \\exp[-2y_i*f(x_i; \\theta)]\\}\n","\\end{equation}\n","<br>\n","Given models referenced by $\\theta_m$, the best among them, as suggested by the binomial deviance, is that $\\theta_{m^*}$ for which $L(\\theta_{m^*})$ is minimum."]},{"cell_type":"markdown","metadata":{"id":"Hm97U-vmF9-k"},"source":["#### Implementation"]},{"cell_type":"code","metadata":{"id":"VLaIlB-1F9-l","executionInfo":{"status":"ok","timestamp":1632601582347,"user_tz":180,"elapsed":49,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}}},"source":["# Function that calculates binomial deviance for a set of data points:\n","def binomial_deviance(y, p):\n","    \"y is a true binary label, while p is an estimated probability for reference class.\"\n","    return np.sum(np.log(1 + np.exp(-2*y*p)))"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LeXkAVJtF9-n","executionInfo":{"status":"ok","timestamp":1632601582349,"user_tz":180,"elapsed":50,"user":{"displayName":"Matheus Rosso","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07497572953789637511"}},"outputId":"4854951a-39a3-45ca-c984-30e31190d7b5"},"source":["print(f'Binomial deviance: {binomial_deviance(scores[\"y_true\"], scores[\"y_pred\"]):.4f}.')"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Binomial deviance: 2460.5717.\n"]}]},{"cell_type":"markdown","metadata":{"id":"RQiYV52bF9-o"},"source":["<a id='multinomial_deviance'> </a>"]},{"cell_type":"markdown","metadata":{"id":"GmdaQvcFF9-r"},"source":["### Multinomial deviance"]},{"cell_type":"markdown","metadata":{"id":"6RdfSaW_F9-s"},"source":["Another common loss function, this time used when estimating statistical learning methods for multinomial classification problems. Considering a probability prediction for class $k$ $f_k(x_i; \\theta)$ constructed from inputs $x_i$ and parameters $\\theta$, the **multinomial deviance** is given by:\n","\\begin{equation}\n","L(\\theta) = -\\sum_{i=1}^N\\sum_{k=1}^K y_{ik}\\log(f_k(x_i))\n","\\end{equation}\n","Since $L(\\theta)$ is a loss function minimized during fitting procedures, the smaller $L(\\theta)$ the better is the model referenced by $\\theta$."]},{"cell_type":"markdown","metadata":{"id":"IbCcSrt-F9-s"},"source":["<a id='references'> </a>"]},{"cell_type":"markdown","metadata":{"id":"qYPrtR63F9-t"},"source":["## References"]},{"cell_type":"markdown","metadata":{"id":"QDdC5CzWF9-y"},"source":["[How to Use ROC Curves and Precision-Recall Curves for Classification in Python](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/): discussion and implementation of ROC-AUC and precision-recall as performance metrics for binary classification.\n","\n","[Probabilistic Interpretation of AUC](https://www.alexejgossmann.com/auc/): probabilistic interpretation for ROC-AUC statistic.\n","\n","[Matthews Correlation Coefficient is The Best Classification Metric Youve Never Heard Of](https://towardsdatascience.com/the-best-classification-metric-youve-never-heard-of-the-matthews-correlation-coefficient-3bf50a2f3e9a): reference about MCC and disadvantages of other metris.\n","\n","[Multi-Class Metrics Made Simple, Part I: Precision and Recall](https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2) and [Multi-Class Metrics Made Simple, Part II: the F1-score](https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1): discuss about metrics for multi-class classification, as extensions of metrics for binary classification.\n","\n","[Multi-Class Metrics Made Simple, Part III: the Kappa Score (aka Cohens Kappa Coefficient)](https://towardsdatascience.com/multi-class-metrics-made-simple-the-kappa-score-aka-cohens-kappa-coefficient-bdea137af09c): presents Kappa coefficient for multi-class classification.\n","\n","[Cross-validation Metrics for Evaluating Classification Performance on Imbalanced Data](https://www.researchgate.net/publication/338439986_Cross-validation_Metrics_for_Evaluating_Classification_Performance_on_Imbalanced_Data): nice paper about performance metrics for imbalanced classification tasks."]},{"cell_type":"code","metadata":{"id":"JMyB6SJvF9-0"},"source":[""],"execution_count":null,"outputs":[]}]}
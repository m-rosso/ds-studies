{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics for classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification problems bring several different concepts when it comes to assess the performance of a classifier. First of all, classification may be based either on *binary* or *multinomial* response variables. Although similar, these two settings of classification require attention when calculating metrics for evaluation. In addition to statistics suited for multinomial problems (for example, multinomial deviance), some metrics used for binary problems, such as precision, recall, and F1 score, should be calculated for each class separetely (see references for sources with detailed discussion on metrics for multiclass classification).\n",
    "<br>\n",
    "<br>\n",
    "This notebook focus on performance metrics for binary classification, even though some ideas or results may also hold for multinomial problems. A *statistical learning method* is applied to estimate a model $f(.)$ referenced by *parameters* $\\theta$. These parameters determine how inputs $X$ define the output $Y$. When the response variable is binary, $Y \\in \\{0, 1\\}$, such as for the dataset used here, the estimation of $\\theta$ leads to the calculation of a *score* $P(y = 1|x, \\hat{\\theta})$ for a given data point $x$.\n",
    "<br>\n",
    "<br>\n",
    "Metrics of performance for binary classification problems may either compare true labels with scores or true labels with predicted classes, where these follow from opposing scores with a predefined threshold to allocate data points to $Y = 1$ or to $Y = 0$. Not just that, some metrics may be explicitly dependent on the choice of a given threshold, or may consider several diffent thresholds, or even may not use any threshold at all. The approach here has separated metrics into those whose value consists on a rate and those that report some kind of score. The former class of metrics is prone to use a given threshold in its calculation.\n",
    "<br>\n",
    "<br>\n",
    "Two relevant subjects concerning classification point to *class imbalance* and *domain knowledge*. A given dataset is imbalanced when the prior probability of some class, $P(Y = 1)$ for binary problems, is too low or too high. This should raise special care when applying and interpreting any performance metric. Domaing knowledge is also crucial, since different costs may follow from different sorts of misclassification, even when there are only two possible classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "1. [Libraries](#libraries)<a href='#libraries'></a>.\n",
    "2. [Importing datasets](#imports)<a href='#imports'></a>.\n",
    "<br>\n",
    "<br>\n",
    "3. [Rate metrics](#rate)<a href='#rate'> </a>.\n",
    "    * [Confusion matrix](#conf_matrix)<a href='#conf_matrix'></a>.\n",
    "    * [Rates from confusion matrix](#rates_conf_matrix)<a href='#rates_conf_matrix'></a>\n",
    "<br>\n",
    "<br>\n",
    "4. [Score metrics](#score)<a href='#score'></a>.\n",
    "    * [ROC curve](#roc)<a href='#roc'></a>.\n",
    "    * [Precision-recall](#precision_recall)<a href='#precision_recall'></a>.\n",
    "    * [F1 score](#F1)<a href='#F1'></a>.\n",
    "    * [Brier score](#brier_score)<a href='#brier_score'></a>.\n",
    "    * [Binomial deviance](#binomial_deviance)<a href='#binomial_deviance'></a>.\n",
    "    * [Multinomial deviance](#multinomial_deviance)<a href='#multinomial_deviance'></a>.\n",
    "<br>\n",
    "<br>\n",
    "5. [References](#references)<a href='#references'></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='libraries'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "from sklearn.metrics import auc, roc_curve, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>epoch</th>\n",
       "      <th>y</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10492</td>\n",
       "      <td>932115</td>\n",
       "      <td>1.581295e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10493</td>\n",
       "      <td>932116</td>\n",
       "      <td>1.581295e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10494</td>\n",
       "      <td>932117</td>\n",
       "      <td>1.581295e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10495</td>\n",
       "      <td>932119</td>\n",
       "      <td>1.581296e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10496</td>\n",
       "      <td>932121</td>\n",
       "      <td>1.581296e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id         epoch    y     score\n",
       "10492   932115  1.581295e+12  0.0  0.000569\n",
       "10493   932116  1.581295e+12  0.0  0.053238\n",
       "10494   932117  1.581295e+12  0.0  0.013792\n",
       "10495   932119  1.581296e+12  0.0  0.008181\n",
       "10496   932121  1.581296e+12  0.0  0.001230"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data (only id, epoch, and true label variables):\n",
    "os.chdir('/home/matheus_rosso/Arquivo/Features/Datasets/')\n",
    "df = pd.read_csv('dataset_1424.csv', dtype={'order_id': str}, usecols=['order_id', 'epoch', 'y'])\n",
    "\n",
    "# Scores estimated through logistic regression for test set observations:\n",
    "os.chdir('/home/matheus_rosso/Arquivo/Modelos Hier√°rquicos/Datasets/Reference Models')\n",
    "scores = pd.read_json('Scores/test_scores_log_1424.json')\n",
    "\n",
    "# Dataframe with score and true label:\n",
    "scores = pd.concat([df, scores], axis=1)\n",
    "scores.columns = ['y', 'order_id', 'epoch', 'score']\n",
    "scores = scores[['order_id', 'epoch', 'y', 'score']]\n",
    "scores.dropna(inplace=True)\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rate'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first kind of metrics for classification performance requires the definition of a *threshold* above which an estimated probability of $Y = 1$ points to predicting $\\hat{Y} = 1$, and below which an estimated probability indicates $\\hat{Y} = 0$. Although these metrics are more precise to assess how good a model is to accomplish its classification task, they rely on the definition of a threshold parameter, which is particularly tricky when the binary response variable is highly imbalanced, since $0.5$ is inappropriate in such contexts where the prior rate for $Y = 1$ is too lower or too higher than that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for predicting class from estimated probability:\n",
    "def class_pred(x, threshold=0.5):\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting classes:\n",
    "thres = 0.2\n",
    "scores['class_pred'] = scores['score'].apply(class_pred, threshold=thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conf_matrix'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In binary classification problems, with a response variable $Y \\in \\{0, 1\\}$, there are two kinds of errors when predicting the label for $Y$: **false negative (type-II error)**, that occurs when $\\hat{Y} = 0$ and $Y = 1$, and **false positive (type-I error)**, that holds when $\\hat{Y} = 1$ and $Y = 0$. Analogously, there are also two kinds of correct predictions: **true negative**, when $Y = \\hat{Y} = 0$, and **true positive**, when $Y = \\hat{Y} = 1$. Confusion matrix, that actually applies similarly to multiclass classification problems, summarizes all possible events when predicting labels from a given dataset.\n",
    "<br>\n",
    "<br>\n",
    "Not only the threshold should be chosen carefully when rate metrics are used to assess classification performance, but also which metric to focused on, since false negatives may produce more damage than false positives in some contexts, and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThreshold:\u001b[0m 0.2.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_true</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8516</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_pred     0     1\n",
       "y_true            \n",
       "0       8516   495\n",
       "1        364  1117"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix implementation:\n",
    "conf_matrix = pd.DataFrame(data=confusion_matrix(scores['y'], scores['class_pred']))\n",
    "conf_matrix.index.name = 'y_true'\n",
    "conf_matrix.columns.name = 'y_pred'\n",
    "\n",
    "print('\\033[1mThreshold:\\033[0m ' + str(thres) + '.')\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFalse negatives (y_pred = 0 and y_true = 1)\u001b[0m: 364.\n"
     ]
    }
   ],
   "source": [
    "# False negatives:\n",
    "FN = conf_matrix.iloc[1,0]\n",
    "print('\\033[1mFalse negatives (y_pred = 0 and y_true = 1)\\033[0m: ' + str(FN) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrue negatives (y_pred = 0 and y_true = 0)\u001b[0m: 8516.\n"
     ]
    }
   ],
   "source": [
    "# True negatives:\n",
    "TN = conf_matrix.iloc[0,0]\n",
    "print('\\033[1mTrue negatives (y_pred = 0 and y_true = 0)\\033[0m: ' + str(TN) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFalse positives (y_pred = 1 and y_true = 0)\u001b[0m: 495.\n"
     ]
    }
   ],
   "source": [
    "# False positives:\n",
    "FP = conf_matrix.iloc[0,1]\n",
    "print('\\033[1mFalse positives (y_pred = 1 and y_true = 0)\\033[0m: ' + str(FP) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrue positives (y_pred = 1 and y_true = 1)\u001b[0m: 1117.\n"
     ]
    }
   ],
   "source": [
    "# True positives:\n",
    "TP = conf_matrix.iloc[1,1]\n",
    "print('\\033[1mTrue positives (y_pred = 1 and y_true = 1)\\033[0m: ' + str(TP) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rates_conf_matrix'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rates from confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False negative rate (*miss rate*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **false negative rate** is given by the ratio between false negatives and positives:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "\\displaystyle fnr = \\frac{FN}{P} = \\frac{FN}{(FN + TP)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFalse negative rate (miss rate):\u001b[0m 24.58%.\n"
     ]
    }
   ],
   "source": [
    "fnr = FN/(FN + TP)\n",
    "print('\\033[1mFalse negative rate (miss rate):\\033[0m ' + str(round((fnr*100), 2)) + '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False positive rate (*fall out*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the **false positive rate** is given by the ratio between false positives and negatives:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "\\displaystyle fpr = \\frac{FP}{N} = \\frac{FP}{(FP + TN)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFalse positive rate (fall out):\u001b[0m 5.49%.\n"
     ]
    }
   ],
   "source": [
    "fpr = FP/(FP + TN)\n",
    "print('\\033[1mFalse positive rate (fall out):\\033[0m ' + str(round((fpr*100), 2)) + '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive predictive value (*precision*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **positive predictive value**, also known as **precision**, is based on the total number of positive predictions $\\hat{Y} = 1$. Then, it is given by the ratio between true positives and predicted positives:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "\\displaystyle precision = \\frac{TP}{\\hat{P}} = \\frac{TP}{(FP + TP)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPositive predictive value (precision):\u001b[0m 69.29%.\n"
     ]
    }
   ],
   "source": [
    "prec = TP/(FP + TP)\n",
    "print('\\033[1mPositive predictive value (precision):\\033[0m ' + str(round((prec*100), 2)) + '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensitivity (*recall*, or *true positive rate*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **true positive rate**, also defined as **recall** or **sensitivity**, focus on true positives, but has actual positives as the reference:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "\\displaystyle recall = \\frac{TP}{P} = \\frac{TP}{(FN + TP)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSensitivity (recall, or true positive rate):\u001b[0m 75.42%.\n"
     ]
    }
   ],
   "source": [
    "rec = TP/(FN + TP)\n",
    "print('\\033[1mSensitivity (recall, or true positive rate):\\033[0m ' + str(round((rec*100), 2)) + '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative predictive value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **negative predictive value** is analogous to precision, but focused on true negatives:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "\\displaystyle neg\\_pred = \\frac{TN}{\\hat{N}} = \\frac{TN}{(FN + TN)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNegative predictive value:\u001b[0m 95.9%.\n"
     ]
    }
   ],
   "source": [
    "neg_pred = TN/(FN + TN)\n",
    "print('\\033[1mNegative predictive value:\\033[0m ' + str(round((neg_pred*100), 2)) + '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specificity (*true negative rate*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **specificity**, or **true negative rate** is similar to negative predictive value, but having as reference actual negatives instead of predicted negatives. Besides, is given by the complement to false positive rate (fall out):\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "\\displaystyle specificity = \\frac{TN}{N} = \\frac{TN}{(FP + TN)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSpecificity (true negative rate):\u001b[0m 94.51%.\n"
     ]
    }
   ],
   "source": [
    "tnr = TN/(FP + TN)\n",
    "print('\\033[1mSpecificity (true negative rate):\\033[0m ' + str(round((tnr*100), 2)) + '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False discovery rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **false discovery rate** is analogous to precision, but focused on false positives instead of true positives:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "\\displaystyle false\\_disc = \\frac{FP}{\\hat{P}} = \\frac{TP}{(FP + TP)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFalse discovery rate:\u001b[0m 30.71%.\n"
     ]
    }
   ],
   "source": [
    "false_disc = FP/(FP + TP)\n",
    "print('\\033[1mFalse discovery rate:\\033[0m ' + str(round((false_disc*100), 2)) + '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **error rate** consists on a loss function to be minimized when estimating a classification model, since it aggregates all possible errors when classifying a binary response variable (even though it also applies for multiclass classification problems). Therefore, this rate is given by dividing the sum of false negatives and false positives by the number of observations:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "\\displaystyle err = \\frac{(FN + FP)}{(FN + TN + FP + TP)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mError rate:\u001b[0m 8.19%.\n"
     ]
    }
   ],
   "source": [
    "err = (FN + FP)/(FN + TN + FP + TP)\n",
    "print('\\033[1mError rate:\\033[0m ' + str(round((err*100), 2)) + '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='score'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a type of metrics for classification performance that does not depend on the choice of threshold, which is particularly useful for comparing different classifiers. Moreover, these metrics reveal more clearly how good is the performance of a classifier, since they condensate information into a single statistic. Basically, they can be divided into two subtypes:\n",
    "1. Those combining rates from confusion matrix ([ROC](#roc)<a href='#roc'></a>, [precision-recall](#roc)<a href='#roc'></a> curves, [F1 score](#F1)<a href='#F1'></a>).\n",
    "2. Those consisting on loss functions for classification ([Brier score](#brier_score)<a href='#brier_score'></a>, [deviance](#binomial_deviance)<a href='#binomial_deviance'></a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='roc'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC stands for **Receiver Operating Characteristic**, and explores the fact that rates such as false positive rate ($fpr = FP/N = FP/(FP + TN)$) and true positive rate ($tpr = TP/(FN + TP)$) are defined as a function of the threshold that assigns each data point to a class, given its estimated score.\n",
    "<br>\n",
    "<br>\n",
    "The construction of a ROC curve involves calculating $fpr$ and $tpr$ for several different threshold, then plotting each $fpr$-$tpr$ pair in a plot where the x-axis receives the $fpr$ value, while the y-axis denotes the $tpr$ value. Consequently, a classifier with good performance has its ROC curve located near to the top-left corner of the plot, suggesting the existence of thresholds for which the $fpr$ is very low (and $tnr$ is very high) - left portion - and the $tpr$ is very high (and $fnr$ is very low) - top portion.\n",
    "<br>\n",
    "<br>\n",
    "The baseline for ROC curve is given by the line for which $tpr = fpr$, reflecting a classifier that has as many chances of correctly predicting $Y = 1$ as of wrongly guessing positives. When the classes are balanced, such classifier is equivalent to random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation with sklearn:\n",
    "fpr, tpr, threshold = roc_curve(scores['y'], scores['score'])\n",
    "auc_roc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ff0285b50>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "sns.lineplot(fpr, tpr)\n",
    "plt.plot(np.linspace(0, 1, 1000), np.linspace(0, 1, 1000), '--', linewidth=1, color='black')\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.text(0.82, 0.08, 'AUC = ' + str(round(auc_roc, 4)), fontsize=10, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC-AUC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance information provided by a given ROC curve is summarized through the area under the curve (AUC). The higher its value, the nearer the curve is to the top-left corner of the plot, thus suggesting a good classification performance. When it comes to comparing different classifiers, each referenced by $\\theta_m$, the best model among them is that with the highest ROC-AUC value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9474550236484165"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Direct implementation with sklearn:\n",
    "roc_auc_score(scores['y'], scores['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9474550236484165"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indirect implementation:\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='precision_recall'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision** is given by the positive predictive value $TP/\\hat{P} = TP/(FP + TP)$, while **recall** is equal to the true positive rate, i.e., the sensitivity $TP/P = TP/(FN + TP)$. Thus, the reference is what differences precision from recall, where the first is constructed relatively from the predictions of label $\\hat{Y} = 1$ and the second is based on the number of actual positives $Y = 1$. Both precision and recall should be maximized by a classifier.\n",
    "<br>\n",
    "<br>\n",
    "Precision and recall focus mainly in the correct prediction of label $Y = 1$, and therefore is relevant for contexts where there is a high imbalance between the classes of a binary response variable $Y$.\n",
    "<br>\n",
    "<br>\n",
    "Since $FP$, $TP$, $FN$ and $TN$ are all entities defined by comparing a score with a given threshold, both precision and recall vary across different values for the threshold. Consequently, it is possible to plot precision-recall pairs for different thresholds, and this gives rise to the **precision-recall curve**. Such a plot has the x-axis given by recall and y-axis by precision.\n",
    "<br>\n",
    "<br>\n",
    "The baseline for precision-recall curve is a horizontal line centered in the value of $P/(P + N)$, and the farthest the curve is to the baseline the better will be the classification model, revealing that the classifier has ability to distinguish between classes, being preferred to the random guess or the constant prediction. Irrespective of the baseline, the perfect scenario is to have a precision-recall curve touching the top-right extreme $(1, 1)$, revealing that there is one threshold for which perfect prediction of label $Y = 1$ is possible.\n",
    "<br>\n",
    "<br>\n",
    "**Note:** since the ROC-AUC statistic uses $fpr$ (the inverse of $tnr$) in its calculation, precision-recall may be preferred to it when the data is highly imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average precision score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curve is very convenient to fastly assess a classification performance. However, in order to compare different classifiers, it would be preferred to summarize mathematically a given precision-recall curve. The **average precision score** is a weighted mean for precision where the weights are given by the change in recall from a threshold $t-1$ to another threshold $t$:\n",
    "\\begin{equation}\n",
    "AP = \\sum_{t=1}^T(recall_t - recall_{t-1})precision_t\n",
    "\\end{equation}\n",
    "From this expression, a classifier referenced by $\\theta_m$ is better than another constructed upon a parameter vector $\\theta_{m'}$ if its average precision score is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7972092373257834\n"
     ]
    }
   ],
   "source": [
    "# Implementation with sklearn:\n",
    "avg_prec = average_precision_score(scores['y'], scores['score'])\n",
    "print(avg_prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-recall AUC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of summarizing the information provided by a precision-recall curve is to compute the **area under the curve**, where the higher it is the better, since the closer the curve will be to the top-right corner of the plot.\n",
    "<br>\n",
    "<br>\n",
    "**Note:** although very similiar, precision-recall AUC and average precision score may be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mArea under the curve:\u001b[0m 0.7971.\n",
      "\u001b[1mBaseline:\u001b[0m 0.1412.\n"
     ]
    }
   ],
   "source": [
    "# Implementation with sklearn:\n",
    "precision, recall, threshold = precision_recall_curve(scores['y'], scores['score'])\n",
    "auc_prec_rec = auc(recall, precision)\n",
    "ref_line = sum(scores.y==1)/len(scores.y)\n",
    "print('\\033[1mArea under the curve:\\033[0m ' + str(round(auc_prec_rec, 4)) + '.')\n",
    "print('\\033[1mBaseline:\\033[0m ' + str(round(ref_line, 4)) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c40888fd0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Precision-recall curve:\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "sns.lineplot(x = recall, y = precision)\n",
    "\n",
    "plt.axhline(ref_line, color='black', ls='--', linewidth=1)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-recall curve')\n",
    "plt.text(0.85, 1, 'AUC = ' + str(round(auc_prec_rec, 4)), fontsize=10, verticalalignment='top')\n",
    "plt.text(0.85, 0.95, 'AP = ' + str(round(avg_prec, 4)), fontsize=10, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='F1'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **F1 score** is another metric based on precision and recall. Conventionally, its defined as the harmonic average of precision and recall, thus given by:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "\\displaystyle F1 = \\frac{2}{precision^{-1} + recall^{-1}} = 2*\\frac{precision*recall}{precision + recall}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "Another definition takes a weight $\\beta$ for how many times recall is considered as important as precision:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "\\displaystyle F1 = (1 + \\beta^2)\\frac{precision*recall}{(\\beta^2)*precision + recall}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "For binary classification problems, main F1 score calculation is as above, while for multiclass classification settings there are mainly three ways to calculate F1: macro-F1, weighted-F1, and micro-F1. *Macro-F1* and *weighted-F1* calculate one F1 score for each class, then averaging all of them through simple average (macro-F1) or using weighted average (weighted-F1), where this weighted average takes the positives of each class as weights. *Micro-F1*, for multiclass classification problems, is given by aggregate true positives divided by aggregate positives, therefore, it is equal to accuracy (1 - error rate). It is worth to notice that micro-F1 for binary classification problems is also equal to accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7227434487220964"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*(prec*rec)/(prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBinary F1 score:\u001b[0m 0.7227434487220964.\n",
      "\u001b[1mMacro-F1 score:\u001b[0m 0.837423811769532.\n",
      "\u001b[1mWeighted-F1 score:\u001b[0m 0.9197287234877163.\n",
      "\u001b[1mMicro-F1 score:\u001b[0m 0.9183187190240183.\n"
     ]
    }
   ],
   "source": [
    "# Implementation with sklearn:\n",
    "print('\\033[1mBinary F1 score:\\033[0m ' + str(f1_score(scores['y'], scores['class_pred'])) + '.')\n",
    "print('\\033[1mMacro-F1 score:\\033[0m ' + str(f1_score(scores['y'], scores['class_pred'],\n",
    "                                                      average='macro')) + '.')\n",
    "print('\\033[1mWeighted-F1 score:\\033[0m ' + str(f1_score(scores['y'], scores['class_pred'],\n",
    "                                                         average='weighted')) + '.')\n",
    "print('\\033[1mMicro-F1 score:\\033[0m ' + str(f1_score(scores['y'], scores['class_pred'],\n",
    "                                                      average='micro')) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMicro-F1 score for binary problems (1 - err):\u001b[0m 0.9183187190240183.\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mMicro-F1 score for binary problems (1 - err):\\033[0m ' + str(1 - err) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='brier_score'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brier score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite of its name, the **Brier score** can be seen as just the mean of squared-error loss function, more commonly used for regression problems. Thus, for a binary response variable $Y$, and considering a probability prediction $f(x_i; \\theta)$ for data point $x_i$, the Brier score is defined by:\n",
    "\\begin{equation}\n",
    "Brier(\\theta) = \\frac{1}{N}\\sum_{i=1}^N [y_i - f(x_i; \\theta)]^2\n",
    "\\end{equation}\n",
    "<br>\n",
    "In a given estimation of $\\theta$, the smaller the Brier score, the better the estimation will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates squared-error for a set of data points:\n",
    "def brier(y, p):\n",
    "    \"y is a true binary label, while p is an estimated probability for reference class.\"\n",
    "    return (1/len(y))*np.sum(np.square(y - p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05890284217547327"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier(scores['y'], scores['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05890284217547327"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementation with sklearn:\n",
    "brier_score_loss(scores['y'], scores['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='binomial_deviance'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial deviance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consists on a common loss function to be minimized when estimating statistical learning methods for binary classification problems. Given a probability prediction $f(x_i; \\theta)$ constructed from inputs $x_i$ and parameters $\\theta$, the following equation shows the expression for the **binomial deviance**:\n",
    "\\begin{equation}\n",
    "L(\\theta) = \\sum_{i=1}^N\\log\\{1 + \\exp[-2y_i*f(x_i; \\theta)]\\}\n",
    "\\end{equation}\n",
    "<br>\n",
    "Given models referenced by $\\theta_m$, the best among them, as suggested by the binomial deviance, is that $\\theta_{m^*}$ for which $L(\\theta_{m^*})$ is minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates binomial deviance for a set of data points:\n",
    "def binomial_deviance(y, p):\n",
    "    \"y is a true binary label, while p is an estimated probability for reference class.\"\n",
    "    return np.sum(np.log(1 + np.exp(-2*y*p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6750.492016872447"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binomial_deviance(scores['y'], scores['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multinomial_deviance'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial deviance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common loss function, this time used when estimating statistical learning methods for multinomial classification problems. Considering a probability prediction for class $k$ $f_k(x_i; \\theta)$ constructed from inputs $x_i$ and parameters $\\theta$, the **multinomial deviance** is given by:\n",
    "\\begin{equation}\n",
    "L(\\theta) = -\\sum_{i=1}^N\\sum_{k=1}^K y_{ik}\\log(f_k(x_i))\n",
    "\\end{equation}\n",
    "Since $L(\\theta)$ is a loss function minimized during fitting procedures, the smaller $L(\\theta)$ the better is the model referenced by $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference 1](https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2): discussion on performance metrics for multiclass classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
